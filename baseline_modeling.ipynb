{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "filename = \"datasets/original_dataset.xlsx\"\n",
    "df = pd.read_excel(filename, engine='openpyxl')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 列出数值型特征\n",
    "numeric_features = ['Long_1', 'Long_2', 'Long_3', 'Long_4', 'Long_5', 'Long_6',\n",
    "                    'Long_7', 'Long_8', 'Long_9', 'Long_10'\n",
    "                    'Short_1', 'Short_2', 'Short_3', 'Short_4', 'Short_5',\n",
    "                    'Short_6', 'Short_7', 'Short_8', 'Short_9', 'Short_10']\n",
    "\n",
    "# 使用线性插值来填充缺失值\n",
    "for feature in numeric_features:\n",
    "    # 创建一个插值函数，这里使用线性插值\n",
    "    interpolator = interp1d(df['submission_year'], df[feature], kind='linear', fill_value='extrapolate')\n",
    "    \n",
    "    # 使用插值函数填充缺失值，并将填充结果转换为Series\n",
    "    interpolated_values = pd.Series(interpolator(df['submission_year']), name=feature)\n",
    "    \n",
    "    # 使用fillna方法填充缺失值\n",
    "    df[feature].fillna(interpolated_values, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the DataFrame\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and validation sets\n",
    "train_df = df[df['TrainVal'] == 'Train_60']\n",
    "val_df = df[df['TrainVal'] == 'Val_40']\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                 'Short_1','Short_2','Short_3','Short_4','Short_5','Short_6',\n",
    "                                 'Short_7','Short_8','Short_9', 'Short_10'])\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_val = val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                             'Short_1','Short_2','Short_3','Short_4','Short_5',\n",
    "                             'Short_6','Short_7','Short_8','Short_9', 'Short_10'])\n",
    "y_val = val_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "}\n",
    "clf = xgb.XGBClassifier()\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "# y_pred = best_clf.predict(X_val_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# best_clf.fit(X_train_new, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = best_clf.predict_proba(X_val)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rategit ')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./images/baseline_result.jpg')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

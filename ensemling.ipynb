{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"datasets/original_dataset.xlsx\"\n",
    "df = pd.read_excel(filename, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/interpolate/_interpolate.py:641: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/interpolate/_interpolate.py:644: RuntimeWarning: invalid value encountered in multiply\n",
      "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/interpolate/_interpolate.py:641: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Long_1</th>\n",
       "      <th>Long_2</th>\n",
       "      <th>Long_3</th>\n",
       "      <th>Long_4</th>\n",
       "      <th>Long_5</th>\n",
       "      <th>Long_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Short_1</th>\n",
       "      <th>Short_2</th>\n",
       "      <th>Short_3</th>\n",
       "      <th>Short_4</th>\n",
       "      <th>Short_5</th>\n",
       "      <th>Short_6</th>\n",
       "      <th>Short_7</th>\n",
       "      <th>Short_8</th>\n",
       "      <th>Short_9</th>\n",
       "      <th>Short_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138413</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>71.118364</td>\n",
       "      <td>8192.698333</td>\n",
       "      <td>83.009946</td>\n",
       "      <td>184541.42500</td>\n",
       "      <td>131154.80</td>\n",
       "      <td>48.671647</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108609</td>\n",
       "      <td>0.630414</td>\n",
       "      <td>50.562971</td>\n",
       "      <td>41071.880000</td>\n",
       "      <td>73.326164</td>\n",
       "      <td>88518.18143</td>\n",
       "      <td>47621.34</td>\n",
       "      <td>58.136132</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6741.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341142</td>\n",
       "      <td>0.985568</td>\n",
       "      <td>41.803426</td>\n",
       "      <td>1587.646667</td>\n",
       "      <td>34.919227</td>\n",
       "      <td>35035.94000</td>\n",
       "      <td>32704.26</td>\n",
       "      <td>11.122347</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9411.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.419549</td>\n",
       "      <td>1.317842</td>\n",
       "      <td>48.831847</td>\n",
       "      <td>15061.066670</td>\n",
       "      <td>42.615211</td>\n",
       "      <td>186000.48000</td>\n",
       "      <td>169718.98</td>\n",
       "      <td>39.008325</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428886</td>\n",
       "      <td>1.104783</td>\n",
       "      <td>48.033749</td>\n",
       "      <td>27213.933330</td>\n",
       "      <td>37.997803</td>\n",
       "      <td>91870.16000</td>\n",
       "      <td>82498.31</td>\n",
       "      <td>35.849088</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Long_1  Long_2  Long_3  \\\n",
       "0      984TAH             2015       0  Train_60  1800.0     6.0     0.0   \n",
       "1      410VKN             2015       0    Val_40  5700.0     8.0     0.0   \n",
       "2      394ETK             2015       1  Train_60   700.0     1.0     0.0   \n",
       "3      036KQK             2015       0  Train_60  1700.0     2.0     0.0   \n",
       "4      996RNP             2015       0  Train_60   600.0     3.0     0.0   \n",
       "...       ...              ...     ...       ...     ...     ...     ...   \n",
       "4594   757VJZ             2017       0  Train_60  3000.0    14.0     0.0   \n",
       "4595   538JZF             2017       1  Train_60  1600.0     0.0     0.0   \n",
       "4596   648WHI             2017       1    Val_40   100.0     3.0  6741.0   \n",
       "4597   899YZB             2017       1    Val_40   300.0     0.0  9411.0   \n",
       "4598   287IWI             2017       1  Train_60   300.0     2.0  1365.0   \n",
       "\n",
       "      Long_4  Long_5  Long_6  ...   Short_1   Short_2    Short_3  \\\n",
       "0      221.0     0.0    15.0  ...       NaN       NaN        NaN   \n",
       "1      221.0    12.0    15.0  ...       NaN       NaN        NaN   \n",
       "2      147.0    17.0    10.0  ...       NaN       NaN        NaN   \n",
       "3      461.0   187.0     6.0  ...       NaN       NaN        NaN   \n",
       "4       96.0    30.0    11.0  ...       NaN       NaN        NaN   \n",
       "...      ...     ...     ...  ...       ...       ...        ...   \n",
       "4594   414.0    37.0    10.5  ...  0.138413  0.496467  71.118364   \n",
       "4595   338.0     3.0     1.0  ...  0.108609  0.630414  50.562971   \n",
       "4596   281.0   198.0     3.0  ...  1.341142  0.985568  41.803426   \n",
       "4597   173.0    44.0     1.0  ...  1.419549  1.317842  48.831847   \n",
       "4598   185.0    74.0     3.0  ...  1.428886  1.104783  48.033749   \n",
       "\n",
       "           Short_4    Short_5       Short_6    Short_7    Short_8   Short_9  \\\n",
       "0              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "1              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "2              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "3              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "4              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "...            ...        ...           ...        ...        ...       ...   \n",
       "4594   8192.698333  83.009946  184541.42500  131154.80  48.671647  0.061366   \n",
       "4595  41071.880000  73.326164   88518.18143   47621.34  58.136132  0.416919   \n",
       "4596   1587.646667  34.919227   35035.94000   32704.26  11.122347  0.064327   \n",
       "4597  15061.066670  42.615211  186000.48000  169718.98  39.008325  0.053133   \n",
       "4598  27213.933330  37.997803   91870.16000   82498.31  35.849088  0.409116   \n",
       "\n",
       "      Short_10  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "4594  0.666667  \n",
       "4595  0.000000  \n",
       "4596  0.666667  \n",
       "4597  0.666667  \n",
       "4598  0.000000  \n",
       "\n",
       "[4599 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data type & selecting feature(baseline model only used long-history feature)\n",
    "numeric_features = ['Long_1', 'Long_2', 'Long_3', 'Long_4', 'Long_5', 'Long_6',\n",
    "                    'Long_7', 'Long_8', 'Long_9', 'Long_10','Short_1','Short_2','Short_3','Short_4','Short_5','Short_6','Short_7','Short_8','Short_9','Short_10']\n",
    "\n",
    "# using linear intepolation\n",
    "for feature in numeric_features:\n",
    "    # create a intepolation function\n",
    "    interpolator = interp1d(df['submission_year'], df[feature], kind='linear', fill_value='extrapolate')\n",
    "    \n",
    "    # fill in NA，transforming the outcome to Series\n",
    "    interpolated_values = pd.Series(interpolator(df['submission_year']), name=feature)\n",
    "    \n",
    "    # using fillna method to fill into NA\n",
    "    df[feature].fillna(interpolated_values, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Long_1</th>\n",
       "      <th>Long_2</th>\n",
       "      <th>Long_3</th>\n",
       "      <th>Long_4</th>\n",
       "      <th>Long_5</th>\n",
       "      <th>Long_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Short_1</th>\n",
       "      <th>Short_2</th>\n",
       "      <th>Short_3</th>\n",
       "      <th>Short_4</th>\n",
       "      <th>Short_5</th>\n",
       "      <th>Short_6</th>\n",
       "      <th>Short_7</th>\n",
       "      <th>Short_8</th>\n",
       "      <th>Short_9</th>\n",
       "      <th>Short_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.940477</td>\n",
       "      <td>66.338224</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.940477</td>\n",
       "      <td>66.338224</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.940477</td>\n",
       "      <td>66.338224</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.940477</td>\n",
       "      <td>66.338224</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.940477</td>\n",
       "      <td>66.338224</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138413</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>71.118364</td>\n",
       "      <td>8192.698333</td>\n",
       "      <td>83.009946</td>\n",
       "      <td>184541.42500</td>\n",
       "      <td>131154.80</td>\n",
       "      <td>48.671647</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108609</td>\n",
       "      <td>0.630414</td>\n",
       "      <td>50.562971</td>\n",
       "      <td>41071.880000</td>\n",
       "      <td>73.326164</td>\n",
       "      <td>88518.18143</td>\n",
       "      <td>47621.34</td>\n",
       "      <td>58.136132</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6741.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341142</td>\n",
       "      <td>0.985568</td>\n",
       "      <td>41.803426</td>\n",
       "      <td>1587.646667</td>\n",
       "      <td>34.919227</td>\n",
       "      <td>35035.94000</td>\n",
       "      <td>32704.26</td>\n",
       "      <td>11.122347</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9411.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.419549</td>\n",
       "      <td>1.317842</td>\n",
       "      <td>48.831847</td>\n",
       "      <td>15061.066670</td>\n",
       "      <td>42.615211</td>\n",
       "      <td>186000.48000</td>\n",
       "      <td>169718.98</td>\n",
       "      <td>39.008325</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428886</td>\n",
       "      <td>1.104783</td>\n",
       "      <td>48.033749</td>\n",
       "      <td>27213.933330</td>\n",
       "      <td>37.997803</td>\n",
       "      <td>91870.16000</td>\n",
       "      <td>82498.31</td>\n",
       "      <td>35.849088</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Long_1  Long_2  Long_3  \\\n",
       "0      984TAH           2015.0     0.0  Train_60  1800.0     6.0     0.0   \n",
       "1      410VKN           2015.0     0.0    Val_40  5700.0     8.0     0.0   \n",
       "2      394ETK           2015.0     1.0  Train_60   700.0     1.0     0.0   \n",
       "3      036KQK           2015.0     0.0  Train_60  1700.0     2.0     0.0   \n",
       "4      996RNP           2015.0     0.0  Train_60   600.0     3.0     0.0   \n",
       "...       ...              ...     ...       ...     ...     ...     ...   \n",
       "4594   757VJZ           2017.0     0.0  Train_60  3000.0    14.0     0.0   \n",
       "4595   538JZF           2017.0     1.0  Train_60  1600.0     0.0     0.0   \n",
       "4596   648WHI           2017.0     1.0    Val_40   100.0     3.0  6741.0   \n",
       "4597   899YZB           2017.0     1.0    Val_40   300.0     0.0  9411.0   \n",
       "4598   287IWI           2017.0     1.0  Train_60   300.0     2.0  1365.0   \n",
       "\n",
       "      Long_4  Long_5  Long_6  ...   Short_1   Short_2    Short_3  \\\n",
       "0      221.0     0.0    15.0  ...  0.745562  0.940477  66.338224   \n",
       "1      221.0    12.0    15.0  ...  0.745562  0.940477  66.338224   \n",
       "2      147.0    17.0    10.0  ...  0.745562  0.940477  66.338224   \n",
       "3      461.0   187.0     6.0  ...  0.745562  0.940477  66.338224   \n",
       "4       96.0    30.0    11.0  ...  0.745562  0.940477  66.338224   \n",
       "...      ...     ...     ...  ...       ...       ...        ...   \n",
       "4594   414.0    37.0    10.5  ...  0.138413  0.496467  71.118364   \n",
       "4595   338.0     3.0     1.0  ...  0.108609  0.630414  50.562971   \n",
       "4596   281.0   198.0     3.0  ...  1.341142  0.985568  41.803426   \n",
       "4597   173.0    44.0     1.0  ...  1.419549  1.317842  48.831847   \n",
       "4598   185.0    74.0     3.0  ...  1.428886  1.104783  48.033749   \n",
       "\n",
       "           Short_4    Short_5       Short_6    Short_7    Short_8   Short_9  \\\n",
       "0      6896.331199  71.340244   42912.46152   25271.78  45.238135  0.162112   \n",
       "1      6896.331199  71.340244   42912.46152   25271.78  45.238135  0.162112   \n",
       "2      6896.331199  71.340244   42912.46152   25271.78  45.238135  0.162112   \n",
       "3      6896.331199  71.340244   42912.46152   25271.78  45.238135  0.162112   \n",
       "4      6896.331199  71.340244   42912.46152   25271.78  45.238135  0.162112   \n",
       "...            ...        ...           ...        ...        ...       ...   \n",
       "4594   8192.698333  83.009946  184541.42500  131154.80  48.671647  0.061366   \n",
       "4595  41071.880000  73.326164   88518.18143   47621.34  58.136132  0.416919   \n",
       "4596   1587.646667  34.919227   35035.94000   32704.26  11.122347  0.064327   \n",
       "4597  15061.066670  42.615211  186000.48000  169718.98  39.008325  0.053133   \n",
       "4598  27213.933330  37.997803   91870.16000   82498.31  35.849088  0.409116   \n",
       "\n",
       "      Short_10  \n",
       "0     0.333333  \n",
       "1     0.333333  \n",
       "2     0.333333  \n",
       "3     0.333333  \n",
       "4     0.333333  \n",
       "...        ...  \n",
       "4594  0.666667  \n",
       "4595  0.000000  \n",
       "4596  0.666667  \n",
       "4597  0.666667  \n",
       "4598  0.000000  \n",
       "\n",
       "[4599 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute the DataFrame\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and validation sets\n",
    "train_df = df[df['TrainVal'] == 'Train_60']\n",
    "val_df = df[df['TrainVal'] == 'Val_40']\n",
    "\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_val= val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_val = val_df['target']\n",
    "\n",
    "feature_columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 0.01\n",
      "Index(['Long_1', 'Long_2', 'Long_3', 'Long_4', 'Long_5', 'Long_6', 'Long_7',\n",
      "       'Long_9', 'Short_3', 'Short_5', 'Short_8'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty=\"l1\", solver=\"liblinear\") #liblinear is a solver for small/mid dataset\n",
    "param_grid = {'C': [0.001,0.01,0.1, 1]}  #The inverse of the regularization strength=>(1/lambda)\n",
    "clf = GridSearchCV(log_reg, param_grid, cv=5) #GridSearch\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best C value:\", clf.best_params_['C'])  #find the best \"c\"\n",
    "best_log_reg = clf.best_estimator_\n",
    "model = SelectFromModel(best_log_reg, prefit=True)\n",
    "X_train_new = model.transform(X_train)\n",
    "X_val_new = model.transform(X_val)\n",
    "model.get_support()\n",
    "selected_features = feature_columns[model.get_support()]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_old_list = []\n",
    "X_train_new_list = []\n",
    "X_train_full_list = []\n",
    "y_train_list = []\n",
    "valid_indices_list = [] \n",
    "for train_index, valid_index in kf.split(train_df):\n",
    "    train_fold = train_df.iloc[train_index]\n",
    "    valid_indices_list.append(valid_index)  # Store the validation indices\n",
    "\n",
    "    # For old features model\n",
    "    X_train_old = train_fold.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                           'Short_1','Short_2','Short_3','Short_4','Short_5','Short_6',\n",
    "                                           'Short_7','Short_8','Short_9', 'Short_10','Long_8', 'Long_10'])\n",
    "    X_train_old_list.append(X_train_old)\n",
    "\n",
    "    # For new features model\n",
    "    X_train_new = train_fold.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                           'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                           'Long_7','Long_8','Long_9', 'Long_10','Short_1','Short_2','Short_4','Short_6','Short_7','Short_9','Short_10'])\n",
    "    X_train_new_list.append(X_train_new)\n",
    "\n",
    "    # For full features model\n",
    "    X_train_full = train_fold.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal','Long_8', 'Long_10','Short_1','Short_2','Short_4','Short_6','Short_7','Short_9','Short_10'])\n",
    "    X_train_full_list.append(X_train_full)\n",
    "\n",
    "    y_train = train_fold['target']\n",
    "    y_train_list.append(y_train)\n",
    "\n",
    "\n",
    "X_val_old = val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                             'Short_1','Short_2','Short_3','Short_4','Short_5',\n",
    "                             'Short_6','Short_7','Short_8','Short_9', 'Short_10', 'Long_8', 'Long_10'])\n",
    "X_val_new = val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                           'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                           'Long_7','Long_8','Long_9', 'Long_10','Short_1','Short_2','Short_4','Short_6','Short_7','Short_9','Short_10'])\n",
    "X_val_full= val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal','Long_8', 'Long_10','Short_1','Short_2','Short_4','Short_6','Short_7','Short_9','Short_10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 (Old data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/a./Project_Creditbly/ensemling.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/a./Project_Creditbly/ensemling.ipynb#X40sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m clf_old \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/a./Project_Creditbly/ensemling.ipynb#X40sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m grid_search_old \u001b[39m=\u001b[39m GridSearchCV(clf_old, param_grid, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/a./Project_Creditbly/ensemling.ipynb#X40sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m grid_search_old\u001b[39m.\u001b[39;49mfit(X_train_old, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/a./Project_Creditbly/ensemling.ipynb#X40sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m best_clf_old \u001b[39m=\u001b[39m grid_search_old\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/a./Project_Creditbly/ensemling.ipynb#X40sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# OOF predictions\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[1;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1381\u001b[0m )\n\u001b[1;32m   1382\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1383\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1384\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[1;32m   1398\u001b[0m )\n\u001b[0;32m-> 1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1401\u001b[0m     params,\n\u001b[1;32m   1402\u001b[0m     train_dmatrix,\n\u001b[1;32m   1403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1404\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1405\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1406\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1407\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1408\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1409\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1410\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1411\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1412\u001b[0m )\n\u001b[1;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1415\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1777\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1779\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1780\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.015,0.02,0.025],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [40,50,70,90],\n",
    "    'subsample': [0.15,0.2, 0.3, 0.4],\n",
    "    'colsample_bytree': [ 0.85, 0.89, 0.93],\n",
    "}\n",
    "scores_old_list = []\n",
    "scores_new_list = []\n",
    "scores_full_list = []\n",
    "oof_scores_old = np.zeros(len(train_df))\n",
    "oof_scores_new = np.zeros(len(train_df))\n",
    "oof_scores_full = np.zeros(len(train_df))\n",
    "for idx in range(2):\n",
    "    # Extract data for the current fold\n",
    "    X_train_old = X_train_old_list[idx]\n",
    "    y_train = y_train_list[idx]\n",
    "    \n",
    "    # Extract the \"left-out\" fold data for OOF predictions\n",
    "    valid_index = valid_indices_list[idx]\n",
    "    X_oof_old = train_df.iloc[valid_index].drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                                         'Short_1','Short_2','Short_3','Short_4','Short_5','Short_6',\n",
    "                                                         'Short_7','Short_8','Short_9', 'Short_10','Long_8', 'Long_10'])\n",
    "    y_oof = train_df['target'].iloc[valid_index]\n",
    "\n",
    "    # Train the 'old' model\n",
    "    clf_old = xgb.XGBClassifier()\n",
    "    grid_search_old = GridSearchCV(clf_old, param_grid, scoring='roc_auc', cv=3, verbose=1)\n",
    "    grid_search_old.fit(X_train_old, y_train)\n",
    "    best_clf_old = grid_search_old.best_estimator_\n",
    "    \n",
    "    # OOF predictions\n",
    "    oof_scores_old[valid_index] = best_clf_old.predict_proba(X_oof_old)[:, 1]\n",
    "    \n",
    "    # Predictions on the validation dataset\n",
    "    scores_old = best_clf_old.predict_proba(X_val_old)[:, 1]\n",
    "    scores_old_list.append(scores_old)\n",
    "print(\"Best parameters for 'old' model after all iterations:\", grid_search_old.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 (New data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "Best parameters for 'old' model after all iterations: {'colsample_bytree': 0.85, 'learning_rate': 0.015, 'max_depth': 3, 'n_estimators': 70, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_new = {\n",
    "    'colsample_bytree': [0.6, 0.65, 0.7, 0.75],\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.02],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [30, 40, 50, 60, 70],\n",
    "    'subsample': [0.85, 0.9, 0.95]\n",
    "}\n",
    "\n",
    "for idx in range(2):\n",
    "    # Extract data for the current fold\n",
    "    X_train_new = X_train_new_list[idx]\n",
    "    y_train = y_train_list[idx]\n",
    "    \n",
    "    # Extract the \"left-out\" fold data for OOF predictions\n",
    "    valid_index = valid_indices_list[idx]\n",
    "    X_oof_new = train_df.iloc[valid_index].drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                           'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                           'Long_7','Long_8','Long_9', 'Long_10','Short_1','Short_2','Short_4','Short_6','Short_7','Short_9','Short_10'])\n",
    "    y_oof = train_df['target'].iloc[valid_index]\n",
    "\n",
    "    clf_new = xgb.XGBClassifier()\n",
    "    grid_search_new = GridSearchCV(clf_new, param_grid, scoring='roc_auc', cv=3, verbose=1)\n",
    "    grid_search_new.fit(X_train_new, y_train)\n",
    "    best_clf_new = grid_search_new.best_estimator_\n",
    "    \n",
    "    # OOF predictions\n",
    "    oof_scores_new[valid_index] = best_clf_new.predict_proba(X_oof_new)[:, 1]\n",
    "    \n",
    "    # Predictions on the validation dataset\n",
    "    scores_new = best_clf_new.predict_proba(X_val_new)[:, 1]\n",
    "    scores_new_list.append(scores_new)\n",
    "print(\"Best parameters for 'old' model after all iterations:\", grid_search_new.best_params_)\n",
    "\n",
    "\n",
    "# Predict using the best model\n",
    "# y_pred = best_clf.predict(X_val_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 (New + Old data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2400 candidates, totalling 7200 fits\n",
      "Fitting 3 folds for each of 2400 candidates, totalling 7200 fits\n",
      "Best parameters for 'old' model after all iterations: {'colsample_bytree': 0.6, 'learning_rate': 0.02, 'max_depth': 2, 'n_estimators': 80, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'colsample_bytree': [0.6, 0.65, 0.7, 0.75, 0.8],\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.02],\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'n_estimators': [30, 40, 50, 60, 70, 80],\n",
    "    'subsample': [0.85, 0.9, 0.95, 1]\n",
    "}\n",
    "\n",
    "for idx in range(2):\n",
    "    # Extract data for the current fold\n",
    "    X_train_full= X_train_full_list[idx]\n",
    "    y_train = y_train_list[idx]\n",
    "    \n",
    "    # Extract the \"left-out\" fold data for OOF predictions\n",
    "    valid_index = valid_indices_list[idx]\n",
    "    X_oof_full = train_df.iloc[valid_index].drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal','Long_8', 'Long_10','Short_1','Short_2','Short_4','Short_6','Short_7','Short_9','Short_10'])\n",
    "    y_oof = train_df['target'].iloc[valid_index]\n",
    "\n",
    "    clf_full = xgb.XGBClassifier()\n",
    "    grid_search_full= GridSearchCV(clf_full, param_grid, scoring='roc_auc', cv=3, verbose=1)\n",
    "    grid_search_full.fit(X_train_full, y_train)\n",
    "    best_clf_full = grid_search_full.best_estimator_\n",
    "    \n",
    "    # OOF predictions\n",
    "    oof_scores_full[valid_index] = best_clf_full.predict_proba(X_oof_full)[:, 1]\n",
    "    \n",
    "    # Predictions on the validation dataset\n",
    "    scores_full = best_clf_full.predict_proba(X_val_full)[:, 1]\n",
    "    scores_full_list.append(scores_full)\n",
    "print(\"Best parameters for 'old' model after all iterations:\", grid_search_full.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging probabilities from three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Long_1</th>\n",
       "      <th>Long_2</th>\n",
       "      <th>Long_3</th>\n",
       "      <th>Long_4</th>\n",
       "      <th>Long_5</th>\n",
       "      <th>Long_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Short_4</th>\n",
       "      <th>Short_5</th>\n",
       "      <th>Short_6</th>\n",
       "      <th>Short_7</th>\n",
       "      <th>Short_8</th>\n",
       "      <th>Short_9</th>\n",
       "      <th>Short_10</th>\n",
       "      <th>Model_Old_Score</th>\n",
       "      <th>Model_New_Score</th>\n",
       "      <th>Model_Full_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.317558</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.263457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.322827</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>0.287968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.256972</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.224951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.203247</td>\n",
       "      <td>0.242767</td>\n",
       "      <td>0.214962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6896.331199</td>\n",
       "      <td>71.340244</td>\n",
       "      <td>42912.46152</td>\n",
       "      <td>25271.78</td>\n",
       "      <td>45.238135</td>\n",
       "      <td>0.162112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.268471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8192.698333</td>\n",
       "      <td>83.009946</td>\n",
       "      <td>184541.42500</td>\n",
       "      <td>131154.80</td>\n",
       "      <td>48.671647</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.328966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41071.880000</td>\n",
       "      <td>73.326164</td>\n",
       "      <td>88518.18143</td>\n",
       "      <td>47621.34</td>\n",
       "      <td>58.136132</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214821</td>\n",
       "      <td>0.263209</td>\n",
       "      <td>0.233686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6741.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1587.646667</td>\n",
       "      <td>34.919227</td>\n",
       "      <td>35035.94000</td>\n",
       "      <td>32704.26</td>\n",
       "      <td>11.122347</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.254135</td>\n",
       "      <td>0.206857</td>\n",
       "      <td>0.269194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9411.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15061.066670</td>\n",
       "      <td>42.615211</td>\n",
       "      <td>186000.48000</td>\n",
       "      <td>169718.98</td>\n",
       "      <td>39.008325</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>0.212261</td>\n",
       "      <td>0.279241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27213.933330</td>\n",
       "      <td>37.997803</td>\n",
       "      <td>91870.16000</td>\n",
       "      <td>82498.31</td>\n",
       "      <td>35.849088</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228748</td>\n",
       "      <td>0.203103</td>\n",
       "      <td>0.227475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Long_1  Long_2  Long_3  \\\n",
       "0      984TAH           2015.0     0.0  Train_60  1800.0     6.0     0.0   \n",
       "1      410VKN           2015.0     0.0    Val_40  5700.0     8.0     0.0   \n",
       "2      394ETK           2015.0     1.0  Train_60   700.0     1.0     0.0   \n",
       "3      036KQK           2015.0     0.0  Train_60  1700.0     2.0     0.0   \n",
       "4      996RNP           2015.0     0.0  Train_60   600.0     3.0     0.0   \n",
       "...       ...              ...     ...       ...     ...     ...     ...   \n",
       "4594   757VJZ           2017.0     0.0  Train_60  3000.0    14.0     0.0   \n",
       "4595   538JZF           2017.0     1.0  Train_60  1600.0     0.0     0.0   \n",
       "4596   648WHI           2017.0     1.0    Val_40   100.0     3.0  6741.0   \n",
       "4597   899YZB           2017.0     1.0    Val_40   300.0     0.0  9411.0   \n",
       "4598   287IWI           2017.0     1.0  Train_60   300.0     2.0  1365.0   \n",
       "\n",
       "      Long_4  Long_5  Long_6  ...       Short_4    Short_5       Short_6  \\\n",
       "0      221.0     0.0    15.0  ...   6896.331199  71.340244   42912.46152   \n",
       "1      221.0    12.0    15.0  ...   6896.331199  71.340244   42912.46152   \n",
       "2      147.0    17.0    10.0  ...   6896.331199  71.340244   42912.46152   \n",
       "3      461.0   187.0     6.0  ...   6896.331199  71.340244   42912.46152   \n",
       "4       96.0    30.0    11.0  ...   6896.331199  71.340244   42912.46152   \n",
       "...      ...     ...     ...  ...           ...        ...           ...   \n",
       "4594   414.0    37.0    10.5  ...   8192.698333  83.009946  184541.42500   \n",
       "4595   338.0     3.0     1.0  ...  41071.880000  73.326164   88518.18143   \n",
       "4596   281.0   198.0     3.0  ...   1587.646667  34.919227   35035.94000   \n",
       "4597   173.0    44.0     1.0  ...  15061.066670  42.615211  186000.48000   \n",
       "4598   185.0    74.0     3.0  ...  27213.933330  37.997803   91870.16000   \n",
       "\n",
       "        Short_7    Short_8   Short_9  Short_10  Model_Old_Score  \\\n",
       "0      25271.78  45.238135  0.162112  0.333333         0.317558   \n",
       "1      25271.78  45.238135  0.162112  0.333333         0.322827   \n",
       "2      25271.78  45.238135  0.162112  0.333333         0.256972   \n",
       "3      25271.78  45.238135  0.162112  0.333333         0.203247   \n",
       "4      25271.78  45.238135  0.162112  0.333333         0.284020   \n",
       "...         ...        ...       ...       ...              ...   \n",
       "4594  131154.80  48.671647  0.061366  0.666667         0.271240   \n",
       "4595   47621.34  58.136132  0.416919  0.000000         0.214821   \n",
       "4596   32704.26  11.122347  0.064327  0.666667         0.254135   \n",
       "4597  169718.98  39.008325  0.053133  0.666667         0.302875   \n",
       "4598   82498.31  35.849088  0.409116  0.000000         0.228748   \n",
       "\n",
       "      Model_New_Score  Model_Full_Score  \n",
       "0            0.238687          0.263457  \n",
       "1            0.240727          0.287968  \n",
       "2            0.238687          0.224951  \n",
       "3            0.242767          0.214962  \n",
       "4            0.238687          0.268471  \n",
       "...               ...               ...  \n",
       "4594         0.264418          0.328966  \n",
       "4595         0.263209          0.233686  \n",
       "4596         0.206857          0.269194  \n",
       "4597         0.212261          0.279241  \n",
       "4598         0.203103          0.227475  \n",
       "\n",
       "[4599 rows x 27 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert OOF scores to DataFrame and add UniqueID\n",
    "oof_scores_df_old = pd.DataFrame({'UniqueID': train_df['UniqueID'], 'OOF_Probability (Model old)': oof_scores_old})\n",
    "oof_scores_df_new = pd.DataFrame({'UniqueID': train_df['UniqueID'], 'OOF_Probability (Model new)': oof_scores_new})\n",
    "oof_scores_df_full = pd.DataFrame({'UniqueID': train_df['UniqueID'], 'OOF_Probability (Model full)': oof_scores_full})\n",
    "\n",
    "# Average the validation scores across the folds\n",
    "avg_val_scores_old = np.mean(scores_old_list, axis=0)\n",
    "avg_val_scores_new = np.mean(scores_new_list, axis=0)\n",
    "avg_val_scores_full = np.mean(scores_full_list, axis=0)\n",
    "\n",
    "# Convert averaged validation scores to DataFrame and add UniqueID\n",
    "val_scores_df_old = pd.DataFrame({'UniqueID': val_df['UniqueID'], 'Val_Probability (Model old)': avg_val_scores_old})\n",
    "val_scores_df_new = pd.DataFrame({'UniqueID': val_df['UniqueID'], 'Val_Probability (Model new)': avg_val_scores_new})\n",
    "val_scores_df_full = pd.DataFrame({'UniqueID': val_df['UniqueID'], 'Val_Probability (Model full)': avg_val_scores_full})\n",
    "\n",
    "combined_scores_df_old = pd.concat([\n",
    "    pd.DataFrame({'UniqueID': train_df['UniqueID'], 'Model_Old_Score': oof_scores_old}),\n",
    "    pd.DataFrame({'UniqueID': val_df['UniqueID'], 'Model_Old_Score': avg_val_scores_old})\n",
    "], axis=0)\n",
    "\n",
    "combined_scores_df_new = pd.concat([\n",
    "    pd.DataFrame({'UniqueID': train_df['UniqueID'], 'Model_New_Score': oof_scores_new}),\n",
    "    pd.DataFrame({'UniqueID': val_df['UniqueID'], 'Model_New_Score': avg_val_scores_new})\n",
    "], axis=0)\n",
    "\n",
    "combined_scores_df_full = pd.concat([\n",
    "    pd.DataFrame({'UniqueID': train_df['UniqueID'], 'Model_Full_Score': oof_scores_full}),\n",
    "    pd.DataFrame({'UniqueID': val_df['UniqueID'], 'Model_Full_Score': avg_val_scores_full})\n",
    "], axis=0)\n",
    "\n",
    "# Merge combined scores with the original dataset\n",
    "merged_df = df.copy()\n",
    "merged_df = merged_df.merge(combined_scores_df_old, on='UniqueID', how='left')\n",
    "merged_df = merged_df.merge(combined_scores_df_new, on='UniqueID', how='left')\n",
    "merged_df = merged_df.merge(combined_scores_df_full, on='UniqueID', how='left')\n",
    "merged_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model output to build stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Model_Old_Score</th>\n",
       "      <th>Model_New_Score</th>\n",
       "      <th>Model_Full_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.317558</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.263457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>0.322827</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>0.287968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.256972</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.224951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.203247</td>\n",
       "      <td>0.242767</td>\n",
       "      <td>0.214962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.268471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.328966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.214821</td>\n",
       "      <td>0.263209</td>\n",
       "      <td>0.233686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>0.254135</td>\n",
       "      <td>0.206857</td>\n",
       "      <td>0.269194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>0.302875</td>\n",
       "      <td>0.212261</td>\n",
       "      <td>0.279241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.228748</td>\n",
       "      <td>0.203103</td>\n",
       "      <td>0.227475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Model_Old_Score  \\\n",
       "0      984TAH           2015.0     0.0  Train_60         0.317558   \n",
       "1      410VKN           2015.0     0.0    Val_40         0.322827   \n",
       "2      394ETK           2015.0     1.0  Train_60         0.256972   \n",
       "3      036KQK           2015.0     0.0  Train_60         0.203247   \n",
       "4      996RNP           2015.0     0.0  Train_60         0.284020   \n",
       "...       ...              ...     ...       ...              ...   \n",
       "4594   757VJZ           2017.0     0.0  Train_60         0.271240   \n",
       "4595   538JZF           2017.0     1.0  Train_60         0.214821   \n",
       "4596   648WHI           2017.0     1.0    Val_40         0.254135   \n",
       "4597   899YZB           2017.0     1.0    Val_40         0.302875   \n",
       "4598   287IWI           2017.0     1.0  Train_60         0.228748   \n",
       "\n",
       "      Model_New_Score  Model_Full_Score  \n",
       "0            0.238687          0.263457  \n",
       "1            0.240727          0.287968  \n",
       "2            0.238687          0.224951  \n",
       "3            0.242767          0.214962  \n",
       "4            0.238687          0.268471  \n",
       "...               ...               ...  \n",
       "4594         0.264418          0.328966  \n",
       "4595         0.263209          0.233686  \n",
       "4596         0.206857          0.269194  \n",
       "4597         0.212261          0.279241  \n",
       "4598         0.203103          0.227475  \n",
       "\n",
       "[4599 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df = merged_df.drop(columns=['Short_1','Short_2','Short_3','Short_4','Short_5','Short_6',\n",
    "                                 'Short_7','Short_8','Short_9', 'Short_10',\n",
    "                                  'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                 'Long_7','Long_8','Long_9', 'Long_10'])\n",
    "aggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Model_Old_Score</th>\n",
       "      <th>Model_New_Score</th>\n",
       "      <th>Model_Full_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.317558</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.263457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.256972</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.224951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.203247</td>\n",
       "      <td>0.242767</td>\n",
       "      <td>0.214962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.268471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>283LEL</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.233901</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.202362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>430SZS</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.219449</td>\n",
       "      <td>0.285190</td>\n",
       "      <td>0.249011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593</th>\n",
       "      <td>993OMZ</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.214961</td>\n",
       "      <td>0.259009</td>\n",
       "      <td>0.231068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.328966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.214821</td>\n",
       "      <td>0.263209</td>\n",
       "      <td>0.233686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.228748</td>\n",
       "      <td>0.203103</td>\n",
       "      <td>0.227475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Model_Old_Score  \\\n",
       "0      984TAH           2015.0     0.0  Train_60         0.317558   \n",
       "2      394ETK           2015.0     1.0  Train_60         0.256972   \n",
       "3      036KQK           2015.0     0.0  Train_60         0.203247   \n",
       "4      996RNP           2015.0     0.0  Train_60         0.284020   \n",
       "7      283LEL           2015.0     0.0  Train_60         0.233901   \n",
       "...       ...              ...     ...       ...              ...   \n",
       "4592   430SZS           2017.0     0.0  Train_60         0.219449   \n",
       "4593   993OMZ           2017.0     1.0  Train_60         0.214961   \n",
       "4594   757VJZ           2017.0     0.0  Train_60         0.271240   \n",
       "4595   538JZF           2017.0     1.0  Train_60         0.214821   \n",
       "4598   287IWI           2017.0     1.0  Train_60         0.228748   \n",
       "\n",
       "      Model_New_Score  Model_Full_Score  \n",
       "0            0.238687          0.263457  \n",
       "2            0.238687          0.224951  \n",
       "3            0.242767          0.214962  \n",
       "4            0.238687          0.268471  \n",
       "7            0.238687          0.202362  \n",
       "...               ...               ...  \n",
       "4592         0.285190          0.249011  \n",
       "4593         0.259009          0.231068  \n",
       "4594         0.264418          0.328966  \n",
       "4595         0.263209          0.233686  \n",
       "4598         0.203103          0.227475  \n",
       "\n",
       "[2768 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into training and validation sets\n",
    "train_df_2 = aggregate_df[aggregate_df['TrainVal'] == 'Train_60']\n",
    "val_df_2 = aggregate_df[aggregate_df['TrainVal'] == 'Val_40']\n",
    "\n",
    "# Old Data\n",
    "old_data_end_index = 2763\n",
    "old_data_indices = aggregate_df.iloc[:old_data_end_index].index\n",
    "val_old = val_df_2[val_df.index.isin(old_data_indices)]\n",
    "\n",
    "# New Data\n",
    "new_data_start_index = 2763\n",
    "new_data_indices = aggregate_df.iloc[new_data_start_index:].index\n",
    "val_new = val_df_2[val_df.index.isin(new_data_indices)]\n",
    "\n",
    "# Combined Data (Old + New)\n",
    "val_combined = val_df_2.copy()\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train_2 = train_df_2.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_train_2 = train_df_2['target']\n",
    "\n",
    "X_val_old = val_old.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_val_old = val_old['target']\n",
    "\n",
    "# New Data (from row 2763 onwards)\n",
    "X_val_new = val_new.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_val_new = val_new['target']\n",
    "\n",
    "# Combined Old + New Data\n",
    "X_val_combined = val_combined.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_val_combined = val_combined['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 768 candidates, totalling 2304 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.02, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_2 = {\n",
    "    'colsample_bytree': [0.65, 0.7, 0.75, 0.8],\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.02],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [30, 40, 50, 60],\n",
    "    'subsample': [0.85, 0.9, 0.95, 1]\n",
    "}\n",
    "clf_2 = xgb.XGBClassifier()\n",
    "grid_search_2 = GridSearchCV(clf_2, param_grid_2, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search_2.best_params_)\n",
    "\n",
    "best_clf_2 = grid_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test on full testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# best_clf.fit(X_train_new, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "\n",
    "y_pred_2 = best_clf_2.predict_proba(X_val_combined)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val_combined, y_pred_2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rategit ')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./images/ensembling.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Coefficient:  0.2833772585891683\n"
     ]
    }
   ],
   "source": [
    "# Calculate Gini coefficient\n",
    "gini_coefficient = 2 * roc_auc - 1\n",
    "print(\"Gini Coefficient: \", gini_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  20\n"
     ]
    }
   ],
   "source": [
    "# Calculate numbers of features\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Number of Features: \", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Features:\n",
      " Model_Old_Score     0.504651\n",
      "Model_Full_Score    0.467211\n",
      "Model_New_Score     0.028138\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best model (after hyperparameter tuning)\n",
    "best_clf = grid_search_2.best_estimator_\n",
    "\n",
    "# Get and sort feature importances\n",
    "feature_importances = pd.Series(best_clf.feature_importances_, index=X_train_2.columns).sort_values(ascending=False)\n",
    "\n",
    "# Print the top 5 most important features\n",
    "print(\"Top 5 Features:\\n\", feature_importances.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# best_clf.fit(X_train_new, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "\n",
    "y_pred_2 = best_clf_2.predict_proba(X_val_new)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val_new, y_pred_2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rategit ')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./images/ensembling.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test on old data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# best_clf.fit(X_train_new, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "\n",
    "y_pred_2 = best_clf_2.predict_proba(X_val_old)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val_old, y_pred_2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rategit ')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./images/ensembling.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

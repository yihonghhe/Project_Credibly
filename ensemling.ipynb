{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Long_1</th>\n",
       "      <th>Long_2</th>\n",
       "      <th>Long_3</th>\n",
       "      <th>Long_4</th>\n",
       "      <th>Long_5</th>\n",
       "      <th>Long_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Short_1</th>\n",
       "      <th>Short_2</th>\n",
       "      <th>Short_3</th>\n",
       "      <th>Short_4</th>\n",
       "      <th>Short_5</th>\n",
       "      <th>Short_6</th>\n",
       "      <th>Short_7</th>\n",
       "      <th>Short_8</th>\n",
       "      <th>Short_9</th>\n",
       "      <th>Short_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138413</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>71.118364</td>\n",
       "      <td>8192.698333</td>\n",
       "      <td>83.009946</td>\n",
       "      <td>184541.42500</td>\n",
       "      <td>131154.80</td>\n",
       "      <td>48.671647</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>338.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108609</td>\n",
       "      <td>0.630414</td>\n",
       "      <td>50.562971</td>\n",
       "      <td>41071.880000</td>\n",
       "      <td>73.326164</td>\n",
       "      <td>88518.18143</td>\n",
       "      <td>47621.34</td>\n",
       "      <td>58.136132</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6741.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341142</td>\n",
       "      <td>0.985568</td>\n",
       "      <td>41.803426</td>\n",
       "      <td>1587.646667</td>\n",
       "      <td>34.919227</td>\n",
       "      <td>35035.94000</td>\n",
       "      <td>32704.26</td>\n",
       "      <td>11.122347</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9411.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.419549</td>\n",
       "      <td>1.317842</td>\n",
       "      <td>48.831847</td>\n",
       "      <td>15061.066670</td>\n",
       "      <td>42.615211</td>\n",
       "      <td>186000.48000</td>\n",
       "      <td>169718.98</td>\n",
       "      <td>39.008325</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428886</td>\n",
       "      <td>1.104783</td>\n",
       "      <td>48.033749</td>\n",
       "      <td>27213.933330</td>\n",
       "      <td>37.997803</td>\n",
       "      <td>91870.16000</td>\n",
       "      <td>82498.31</td>\n",
       "      <td>35.849088</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Long_1  Long_2  Long_3  \\\n",
       "0      984TAH             2015       0  Train_60  1800.0     6.0     0.0   \n",
       "1      410VKN             2015       0    Val_40  5700.0     8.0     0.0   \n",
       "2      394ETK             2015       1  Train_60   700.0     1.0     0.0   \n",
       "3      036KQK             2015       0  Train_60  1700.0     2.0     0.0   \n",
       "4      996RNP             2015       0  Train_60   600.0     3.0     0.0   \n",
       "...       ...              ...     ...       ...     ...     ...     ...   \n",
       "4594   757VJZ             2017       0  Train_60  3000.0    14.0     0.0   \n",
       "4595   538JZF             2017       1  Train_60  1600.0     0.0     NaN   \n",
       "4596   648WHI             2017       1    Val_40   100.0     3.0  6741.0   \n",
       "4597   899YZB             2017       1    Val_40   300.0     0.0  9411.0   \n",
       "4598   287IWI             2017       1  Train_60   300.0     2.0  1365.0   \n",
       "\n",
       "      Long_4  Long_5  Long_6  ...   Short_1   Short_2    Short_3  \\\n",
       "0      221.0     0.0    15.0  ...       NaN       NaN        NaN   \n",
       "1      221.0    12.0    15.0  ...       NaN       NaN        NaN   \n",
       "2      147.0    17.0    10.0  ...       NaN       NaN        NaN   \n",
       "3      461.0   187.0     6.0  ...       NaN       NaN        NaN   \n",
       "4       96.0    30.0    11.0  ...       NaN       NaN        NaN   \n",
       "...      ...     ...     ...  ...       ...       ...        ...   \n",
       "4594   414.0    37.0    10.5  ...  0.138413  0.496467  71.118364   \n",
       "4595   338.0     NaN     1.0  ...  0.108609  0.630414  50.562971   \n",
       "4596   281.0   198.0     3.0  ...  1.341142  0.985568  41.803426   \n",
       "4597   173.0    44.0     1.0  ...  1.419549  1.317842  48.831847   \n",
       "4598   185.0    74.0     3.0  ...  1.428886  1.104783  48.033749   \n",
       "\n",
       "           Short_4    Short_5       Short_6    Short_7    Short_8   Short_9  \\\n",
       "0              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "1              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "2              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "3              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "4              NaN        NaN           NaN        NaN        NaN       NaN   \n",
       "...            ...        ...           ...        ...        ...       ...   \n",
       "4594   8192.698333  83.009946  184541.42500  131154.80  48.671647  0.061366   \n",
       "4595  41071.880000  73.326164   88518.18143   47621.34  58.136132  0.416919   \n",
       "4596   1587.646667  34.919227   35035.94000   32704.26  11.122347  0.064327   \n",
       "4597  15061.066670  42.615211  186000.48000  169718.98  39.008325  0.053133   \n",
       "4598  27213.933330  37.997803   91870.16000   82498.31  35.849088  0.409116   \n",
       "\n",
       "      Short_10  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "4594  0.666667  \n",
       "4595  0.000000  \n",
       "4596  0.666667  \n",
       "4597  0.666667  \n",
       "4598  0.000000  \n",
       "\n",
       "[4599 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"datasets/original_dataset.xlsx\"\n",
    "df = pd.read_excel(filename, engine='openpyxl')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and validation sets\n",
    "train_df = df[df['TrainVal'] == 'Train_60']\n",
    "val_df = df[df['TrainVal'] == 'Val_40']\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train_old = train_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                 'Short_1','Short_2','Short_3','Short_4','Short_5','Short_6',\n",
    "                                 'Short_7','Short_8','Short_9', 'Short_10'])\n",
    "X_train_new = train_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                 'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                 'Long_7','Long_8','Long_9', 'Long_10'])\n",
    "X_train_full= train_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_val_old = val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                             'Short_1','Short_2','Short_3','Short_4','Short_5',\n",
    "                             'Short_6','Short_7','Short_8','Short_9', 'Short_10'])\n",
    "X_val_new = val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal',\n",
    "                                 'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                 'Long_7','Long_8','Long_9', 'Long_10'])\n",
    "X_val_full= val_df.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_val = val_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 (Old data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_old = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "}\n",
    "clf_old = xgb.XGBClassifier()\n",
    "grid_search_old = GridSearchCV(clf_old, param_grid_old, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search_old.fit(X_train_old, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search_old.best_params_)\n",
    "\n",
    "best_clf_old = grid_search_old.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "# y_pred = best_clf.predict(X_val_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_old = best_clf_old.predict_proba(X_train_old)[:, 1]\n",
    "val_scores_old = best_clf_old.predict_proba(X_val_old)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 (New data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_new = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "}\n",
    "clf_new = xgb.XGBClassifier()\n",
    "grid_search_new = GridSearchCV(clf_new, param_grid_new, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search_new.fit(X_train_new, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search_new.best_params_)\n",
    "\n",
    "best_clf_new = grid_search_new.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "# y_pred = best_clf.predict(X_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_new = best_clf_new.predict_proba(X_train_new)[:, 1]\n",
    "val_scores_new = best_clf_new.predict_proba(X_val_new)[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 (New + Old data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_full = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "}\n",
    "clf_full = xgb.XGBClassifier()\n",
    "grid_search_full = GridSearchCV(clf_full, param_grid_full, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search_full.fit(X_train_full, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search_full.best_params_)\n",
    "\n",
    "best_clf_full = grid_search_full.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "# y_pred = best_clf.predict(X_val_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_full = best_clf_full.predict_proba(X_train_full)[:, 1]\n",
    "val_scores_full = best_clf_full.predict_proba(X_val_full)[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging probabilities from three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Long_1</th>\n",
       "      <th>Long_2</th>\n",
       "      <th>Long_3</th>\n",
       "      <th>Long_4</th>\n",
       "      <th>Long_5</th>\n",
       "      <th>Long_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Short_4</th>\n",
       "      <th>Short_5</th>\n",
       "      <th>Short_6</th>\n",
       "      <th>Short_7</th>\n",
       "      <th>Short_8</th>\n",
       "      <th>Short_9</th>\n",
       "      <th>Short_10</th>\n",
       "      <th>Probability (Model old)</th>\n",
       "      <th>Probability (Model new)</th>\n",
       "      <th>Probability (Model full)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414460</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.287892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.352568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388046</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373537</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.164835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8192.698333</td>\n",
       "      <td>83.009946</td>\n",
       "      <td>184541.42500</td>\n",
       "      <td>131154.80</td>\n",
       "      <td>48.671647</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.380085</td>\n",
       "      <td>0.440142</td>\n",
       "      <td>0.245470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>338.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41071.880000</td>\n",
       "      <td>73.326164</td>\n",
       "      <td>88518.18143</td>\n",
       "      <td>47621.34</td>\n",
       "      <td>58.136132</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372056</td>\n",
       "      <td>0.409351</td>\n",
       "      <td>0.274810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6741.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1587.646667</td>\n",
       "      <td>34.919227</td>\n",
       "      <td>35035.94000</td>\n",
       "      <td>32704.26</td>\n",
       "      <td>11.122347</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.443616</td>\n",
       "      <td>0.361476</td>\n",
       "      <td>0.328241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9411.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15061.066670</td>\n",
       "      <td>42.615211</td>\n",
       "      <td>186000.48000</td>\n",
       "      <td>169718.98</td>\n",
       "      <td>39.008325</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.434775</td>\n",
       "      <td>0.364307</td>\n",
       "      <td>0.410174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27213.933330</td>\n",
       "      <td>37.997803</td>\n",
       "      <td>91870.16000</td>\n",
       "      <td>82498.31</td>\n",
       "      <td>35.849088</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386336</td>\n",
       "      <td>0.363479</td>\n",
       "      <td>0.244355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Long_1  Long_2  Long_3  \\\n",
       "0      984TAH             2015       0  Train_60  1800.0     6.0     0.0   \n",
       "1      410VKN             2015       0    Val_40  5700.0     8.0     0.0   \n",
       "2      394ETK             2015       1  Train_60   700.0     1.0     0.0   \n",
       "3      036KQK             2015       0  Train_60  1700.0     2.0     0.0   \n",
       "4      996RNP             2015       0  Train_60   600.0     3.0     0.0   \n",
       "...       ...              ...     ...       ...     ...     ...     ...   \n",
       "4594   757VJZ             2017       0  Train_60  3000.0    14.0     0.0   \n",
       "4595   538JZF             2017       1  Train_60  1600.0     0.0     NaN   \n",
       "4596   648WHI             2017       1    Val_40   100.0     3.0  6741.0   \n",
       "4597   899YZB             2017       1    Val_40   300.0     0.0  9411.0   \n",
       "4598   287IWI             2017       1  Train_60   300.0     2.0  1365.0   \n",
       "\n",
       "      Long_4  Long_5  Long_6  ...       Short_4    Short_5       Short_6  \\\n",
       "0      221.0     0.0    15.0  ...           NaN        NaN           NaN   \n",
       "1      221.0    12.0    15.0  ...           NaN        NaN           NaN   \n",
       "2      147.0    17.0    10.0  ...           NaN        NaN           NaN   \n",
       "3      461.0   187.0     6.0  ...           NaN        NaN           NaN   \n",
       "4       96.0    30.0    11.0  ...           NaN        NaN           NaN   \n",
       "...      ...     ...     ...  ...           ...        ...           ...   \n",
       "4594   414.0    37.0    10.5  ...   8192.698333  83.009946  184541.42500   \n",
       "4595   338.0     NaN     1.0  ...  41071.880000  73.326164   88518.18143   \n",
       "4596   281.0   198.0     3.0  ...   1587.646667  34.919227   35035.94000   \n",
       "4597   173.0    44.0     1.0  ...  15061.066670  42.615211  186000.48000   \n",
       "4598   185.0    74.0     3.0  ...  27213.933330  37.997803   91870.16000   \n",
       "\n",
       "        Short_7    Short_8   Short_9  Short_10  Probability (Model old)  \\\n",
       "0           NaN        NaN       NaN       NaN                 0.414460   \n",
       "1           NaN        NaN       NaN       NaN                 0.453624   \n",
       "2           NaN        NaN       NaN       NaN                 0.388046   \n",
       "3           NaN        NaN       NaN       NaN                 0.373537   \n",
       "4           NaN        NaN       NaN       NaN                 0.396929   \n",
       "...         ...        ...       ...       ...                      ...   \n",
       "4594  131154.80  48.671647  0.061366  0.666667                 0.380085   \n",
       "4595   47621.34  58.136132  0.416919  0.000000                 0.372056   \n",
       "4596   32704.26  11.122347  0.064327  0.666667                 0.443616   \n",
       "4597  169718.98  39.008325  0.053133  0.666667                 0.434775   \n",
       "4598   82498.31  35.849088  0.409116  0.000000                 0.386336   \n",
       "\n",
       "      Probability (Model new)  Probability (Model full)  \n",
       "0                    0.394917                  0.287892  \n",
       "1                    0.394917                  0.352568  \n",
       "2                    0.394917                  0.254349  \n",
       "3                    0.394917                  0.164835  \n",
       "4                    0.394917                  0.292500  \n",
       "...                       ...                       ...  \n",
       "4594                 0.440142                  0.245470  \n",
       "4595                 0.409351                  0.274810  \n",
       "4596                 0.361476                  0.328241  \n",
       "4597                 0.364307                  0.410174  \n",
       "4598                 0.363479                  0.244355  \n",
       "\n",
       "[4599 rows x 27 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create new dataframes or copies of the original dataframes to store the scores\n",
    "train_df_old = X_train_old.copy()\n",
    "val_df_old = X_val_old.copy()\n",
    "\n",
    "train_df_new = X_train_new.copy()\n",
    "val_df_new = X_val_new.copy()\n",
    "\n",
    "train_df_full = X_train_full.copy()\n",
    "val_df_full = X_val_full.copy()\n",
    "\n",
    "train_df_old['UniqueID'] = train_df['UniqueID']\n",
    "val_df_old['UniqueID'] = val_df['UniqueID']\n",
    "\n",
    "train_df_new['UniqueID'] = train_df['UniqueID']\n",
    "val_df_new['UniqueID'] = val_df['UniqueID']\n",
    "\n",
    "train_df_full['UniqueID'] = train_df['UniqueID']\n",
    "val_df_full['UniqueID'] = val_df['UniqueID']\n",
    "\n",
    "# Assign the scores to new columns in the corresponding dataframes\n",
    "train_df_old['Probability (Model old)'] = train_scores_old\n",
    "val_df_old['Probability (Model old)'] = val_scores_old\n",
    "\n",
    "train_df_new['Probability (Model new)'] = train_scores_new\n",
    "val_df_new['Probability (Model new)'] = val_scores_new\n",
    "\n",
    "train_df_full['Probability (Model full)'] = train_scores_full\n",
    "val_df_full['Probability (Model full)'] = val_scores_full\n",
    "\n",
    "# Now when you concatenate, the resulting dataframes will have separate columns for each model's scores\n",
    "all_data_with_scores_old = pd.concat([train_df_old, val_df_old], axis=0)\n",
    "all_data_with_scores_new = pd.concat([train_df_new, val_df_new], axis=0)\n",
    "all_data_with_scores_full = pd.concat([train_df_full, val_df_full], axis=0)\n",
    "# Merge the score columns from all_data_with_scores_old, all_data_with_scores_new, and all_data_with_scores_full into df:\n",
    "stage_2_df = df.copy()  # Create a copy of df to avoid modifying it in-place\n",
    "stage_2_df = pd.merge(stage_2_df, all_data_with_scores_old[['UniqueID', 'Probability (Model old)']], on='UniqueID', how='left')\n",
    "stage_2_df = pd.merge(stage_2_df, all_data_with_scores_new[['UniqueID', 'Probability (Model new)']], on='UniqueID', how='left')\n",
    "stage_2_df = pd.merge(stage_2_df, all_data_with_scores_full[['UniqueID', 'Probability (Model full)']], on='UniqueID', how='left')\n",
    "stage_2_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model output to build stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>submission_year</th>\n",
       "      <th>target</th>\n",
       "      <th>TrainVal</th>\n",
       "      <th>Probability (Model old)</th>\n",
       "      <th>Probability (Model new)</th>\n",
       "      <th>Probability (Model full)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984TAH</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.414460</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.287892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410VKN</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.352568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394ETK</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.388046</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.254349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036KQK</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.373537</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.164835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>996RNP</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.394917</td>\n",
       "      <td>0.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>757VJZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.380085</td>\n",
       "      <td>0.440142</td>\n",
       "      <td>0.245470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>538JZF</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.372056</td>\n",
       "      <td>0.409351</td>\n",
       "      <td>0.274810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>648WHI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>0.443616</td>\n",
       "      <td>0.361476</td>\n",
       "      <td>0.328241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>899YZB</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Val_40</td>\n",
       "      <td>0.434775</td>\n",
       "      <td>0.364307</td>\n",
       "      <td>0.410174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>287IWI</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Train_60</td>\n",
       "      <td>0.386336</td>\n",
       "      <td>0.363479</td>\n",
       "      <td>0.244355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4599 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniqueID  submission_year  target  TrainVal  Probability (Model old)  \\\n",
       "0      984TAH             2015       0  Train_60                 0.414460   \n",
       "1      410VKN             2015       0    Val_40                 0.453624   \n",
       "2      394ETK             2015       1  Train_60                 0.388046   \n",
       "3      036KQK             2015       0  Train_60                 0.373537   \n",
       "4      996RNP             2015       0  Train_60                 0.396929   \n",
       "...       ...              ...     ...       ...                      ...   \n",
       "4594   757VJZ             2017       0  Train_60                 0.380085   \n",
       "4595   538JZF             2017       1  Train_60                 0.372056   \n",
       "4596   648WHI             2017       1    Val_40                 0.443616   \n",
       "4597   899YZB             2017       1    Val_40                 0.434775   \n",
       "4598   287IWI             2017       1  Train_60                 0.386336   \n",
       "\n",
       "      Probability (Model new)  Probability (Model full)  \n",
       "0                    0.394917                  0.287892  \n",
       "1                    0.394917                  0.352568  \n",
       "2                    0.394917                  0.254349  \n",
       "3                    0.394917                  0.164835  \n",
       "4                    0.394917                  0.292500  \n",
       "...                       ...                       ...  \n",
       "4594                 0.440142                  0.245470  \n",
       "4595                 0.409351                  0.274810  \n",
       "4596                 0.361476                  0.328241  \n",
       "4597                 0.364307                  0.410174  \n",
       "4598                 0.363479                  0.244355  \n",
       "\n",
       "[4599 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df = stage_2_df.drop(columns=['Short_1','Short_2','Short_3','Short_4','Short_5','Short_6',\n",
    "                                 'Short_7','Short_8','Short_9', 'Short_10',\n",
    "                                  'Long_1','Long_2','Long_3','Long_4','Long_5','Long_6',\n",
    "                                 'Long_7','Long_8','Long_9', 'Long_10'])\n",
    "aggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and validation sets\n",
    "train_df_2 = aggregate_df[aggregate_df['TrainVal'] == 'Train_60']\n",
    "val_df_2 = aggregate_df[aggregate_df['TrainVal'] == 'Val_40']\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train_2 = train_df_2.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_train_2 = train_df_2['target']\n",
    "\n",
    "X_val_2 = val_df_2.drop(columns=['UniqueID', 'submission_year', 'target', 'TrainVal'])\n",
    "y_val_2 = val_df_2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with hyper parameter tuning\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_2 = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "}\n",
    "clf_2 = xgb.XGBClassifier()\n",
    "grid_search_2 = GridSearchCV(clf_2, param_grid_2, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search_2.best_params_)\n",
    "\n",
    "best_clf_2 = grid_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABNDUlEQVR4nO3dd3gUVffA8e9JQgodQhHpAtKbRgGRokgRsBdsWF4sgNjwxY7yw4aKKB2sqLyKiqJIU1AQLCC9VwEhSO8QCCnn98dMyCYkm4Vks9nkfJ4nT6bcmTk72ezZuXfmXlFVjDHGmMyEBDoAY4wxeZslCmOMMV5ZojDGGOOVJQpjjDFeWaIwxhjjlSUKY4wxXlmiyOdEZLWItA10HHmFiDwnIh8E6NjjROSVQBw7p4nInSLy0zlue87vSRH5XUSansu250pEHhGRN3LzmHmNJYpcJCJbReSEiBwTkV3uB0dRfx5TVeur6hx/HiOFiESIyOsiss19nRtFpJ+ISG4cP4N42opIrOcyVX1NVe/30/FERB4VkVUiclxEYkXkaxFp6I/jnSsRGSAi47OzD1X9n6p28OFYZyTHc31Pisg1wFFVXerODxCRBPf/6ZCI/CEiLdJtU1JERrv/b3EislJE7stg33eIyCJ3XztFZLqIXO6ufh+4U0TKnW3M+YUlitx3jaoWBZoATYFnAxvO2RORsExWfQ20AzoDxYDuwIPAUD/EICKS196/Q4HHgEeB0sCFwHdAl5w+kJe/gd8F8Ng9gc/SLfvS/X8qA8zGeQ8CICLhwCygKtACKAH0AwaJSF+Pcn2Bd4HXgPJAFWAUcB2Aqp4EpgN3++NFBQVVtZ9c+gG2Ald5zL8JTPWYbw78ARwClgNtPdaVBj4G/gUOAt95rOsKLHO3+wNolP6YwPnACaC0x7qmwD6gkDv/H2Ctu/8fgaoeZRV4GNgIbMngtbUDTgKV0y1vBiQBNd35OcDrwF/AEeD7dDF5OwdzgFeB393XUhO4z435KLAZeMgtW8Qtkwwcc3/OBwYA490y1dzXdQ+wzT0Xz3scLwr4xD0fa4GngNhM/ra13Nd5qZe//zhgJDDVjXcBUMNj/VBgu3teFgOtPNYNACYC49319wOXAn+652onMAII99imPjATOADsBp4DOgGngAT3nCx3y5YAPnT3swN4BQh1193rnvN3gP3uunuB39z14q7b48a2EmiA8yUhwT3eMeCH9P8HQKgb19/uOVlMuveQWy7c/XtWSndOxnvM13P/nmXd+R5uTEXS7aubG09x93UfA27J4n/3TmB2oD9DAvUT8AAK0k+6f5BK7j/UUHe+ovtP2BnnSq+9O5/ypp8KfAmUAgoBbdzlTd1/hmbuP9097nEiMjjmL8ADHvG8BYxxp68DNgF1gTDgBeAPj7LqfuiUBqIyeG2DgF8zed3/kPoBPsf9IGqA82H+Dakf3Fmdgzk4H+j13RgL4Xxbr4HzYdUGiAMucsu3Jd0HOxknivdxkkJjIB6o6/ma3HNeCViRfn8e++0J/JPF33+c+3oudeP/HzDBY/1dQLS77klgFxDpEXcCcL17bqKAi3ESa5j7WtYCj7vli+F86D8JRLrzzdKfA49jTwLGun+TcjiJPOVvdi+QCDziHiuKtImiI84HfEn371AXqODxml/x8n/QD+f/oLa7bWMgOoNzVx847uVvGe7+vfYBYe6yCcAnGewrzH09HXESZ2LKNl7+dhcBBwL9GRKon7x26V4QfCciR3G+Oe4BXnKX3wVMU9VpqpqsqjOBRUBnEakAXA30VNWDqpqgqr+62z0IjFXVBaqapKqf4HzYNc/g2J8Dt4NTdQPc5i4D54PudVVdq6qJOJfhTUSkqsf2r6vqAVU9kcG+y+B8MGVkp7s+xWequkpVjwP9gVtFJNTbOfDYdpyqrlbVRPc8TFXVv9XxK/AT0CqTODLzf6p6QlWX41zFNHaX3wq85p7zWGCYl31Ee3n9niap6l/uOf4fThUkAKo6XlX3u6/tbSAC5wM0xZ+q+p17bk6o6mJVne+W34rzQd/GLdsV2KWqb6vqSVU9qqoLMgpIRMrjnOPHVfW4qu7BuUK4zaPYv6o63D1W+r9/Ak4iqgOI+x7y5VyAc2X0gqqud/+Gy1V1fwblSuJccaR3q4gcwrnaeAC42T23kMl70l2/z10fDezz2CYzR3GuPgokSxS573pVLYbzbbcOqR+gVYFb3Ea5Q+6b/3KgAlAZ59vMwQz2VxV4Mt12lXGqWdL7BmjhJp7WONUy8zz2M9RjHwdwvuFV9Nh+u5fXtc+NNSMV3PUZ7ecfnCuDMng/BxnGICJXi8h8ETnglu9M2qTki10e03FAyg0G56c7nrfXv5/MX78vx0JE/isia0XksPtaSpD2taR/7ReKyBS3ofYITnJPKV8ZpzrHF1Vx/gY7Pc77WJwriwyP7UlVf8Gp9hoJ7BGR90SkuI/H9jXOgzjJKL2vVLUkTtvCKpyrrBQZvifdNpYy7vr9QBkf2l2KAYd9iDNfskQRIO6333HAYHfRdpxv2iU9foqo6iB3XWkRKZnBrrYDr6bbrrCqfpHBMQ/ifOPuBtyBU+2hHvt5KN1+olT1D89deHlJs4BmIlLZc6GINMP5MPjFY7FnmSo430j3ZXEOzohBRCJwkt9goLz7gTENJ8FlFa8vduJUOWUUd3o/A5VEJOZcDiQirXDaQG4FSrmv5TCprwXOfD2jgXVALVUtjlPXn1J+O3BBJodLv5/tOFehZTzOe3FVre9lm7Q7VB2mqhfjtBNciFOllOV27rFrZFEGnGpREZGKGa1U1X04V9cD3C9C4LwnrxaRIumK34TzeufjtPHE41TpeVMX52qzQLJEEVjvAu1FpDFOI+U1ItJRREJFJNK9vbOSexk/HRglIqVEpJCItHb38T7QU0SauXcCFRGRLiKS0bcvcKqa7gZuJrXaCWAM8KyI1AcQkRIicouvL0RVZ+F8WH4jIvXd19DcfV2jVXWjR/G7RKSeiBQGBgITVTXJ2znI5LDhONUze4FEEbka8LxlczcQLSLnWmXwFc45KeV+QPXJrKD7+kYBX7gxh7vx3yYiz/hwrGI4deV7gTAReRGnsTWrbY4Ax0SkDtDLY90UoIKIPC7ObcvF3KQNznmplnLXmPv++gl4W0SKi0iIiNQQkTb4QEQucd9/hYDjODc1JHscK7OEBfAB8LKI1HLfv41EJDp9IVU9hfPBn2lMqroe5yaMp9xFnwGxwNciUs39v+mIU4U4QFUPq+ph4EVgpIhcLyKF3XJXi8ibHrtvg/M/WCBZogggVd0LfAq8qKrbcRqUn8P5sNiO860s5W/UHeeb9zqcto3H3X0swqmbHYFzeb4Jp6ExM5Nx7tDZ5dbJp8QyCXgDmOBWY6zCaRc5Gzfh3KI4A+dOkvE4d9I8kq7cZzhXU7twGlofdWPI6hykoapH3W2/wnntd7ivL2X9OuALYLNbpZJRdZw3A3E+aLbgfEhNxPn2mZlHSa2COYRTpXID8IMPx/oR57xtwKmOO4n3qi6A/+K85qM4Xxi+TFnhnpv2wDU453kjcIW7OuUW0v0issSdvhsn8a7BOZcT8a0qDZyE9r673T841Tlvues+BOq55/+7DLYdgvP3+wkn6X2I01iekbE4/wfevAU8KCLlVDUe546/7Th3mB1xj/e8qqbEh9se1BfnBo6U910fnFubEZFInCrNT7I4dr4lqTUPxvifiMzBuVMlIE9HZ4eI9AJuU1WfvmmbnCcivwN91H3oLpeO+QjOLbtPZVk4nwrYQzvG5HVuXfcFOPXYtXBuNR0R0KAKOFVtGYBjDs/tY+Y1liiMyVw4TnVHdZyqpAk47RDGFChW9WSMMcYra8w2xhjjVdBVPZUpU0arVasW6DCMMSaoLF68eJ+qlj2XbYMuUVSrVo1FixYFOgxjjAkqIvLPuW5rVU/GGGO8skRhjDHGK0sUxhhjvLJEYYwxxitLFMYYY7yyRGGMMcYrvyUKEflIRPaIyKpM1ouIDBORTSKyQkQu8lcsxhhjzp0/ryjG4YxHm5mrcTpaq4Uz4MhoP8ZijDEFU0Icp9ZPzdYu/PbAnarOFZFqXopcB3zqjrA2X0RKikiFsxhr1xhjTHpJp+DHHnBwPQD9Pj6fpduyN9x3IJ/MrkjagVli3WVnJAoReRDnqoMqVarkSnDGGBN0Dm6Ejy5Ms6hBmcYMm3NNtnYbFF14qOp7wHsAMTEx1t2tMcYAnDgA0+6E47tAQuDIVtbsKsuSHRW469ri0OZt7r5dadP3BNWbvXLOhwlkothB2sHqK7nLjDHGZEaTIXYuxO2BKd1OL447VYhXZrXmrV9bEhoWRvOBD1OzQmkEqHa2gwCnE8hEMRnoIyITgGbAYWufMMYYD8d3w7+/p84nJcCP/4HEuDTFph+4lYfHx7Blm7O8x/1NiY7ObOjxs+e3RCEiXwBtgTIiEgu8BBQCUNUxwDScAcs3AXHAff6KxRhjgk7iSRhzntciO8r/h8e/bMbEKTuBOBo1Ks+YMV1o0aKy1+3Olj/vero9i/UKPOyv4xtjTNBJToLNU2HmgxC3O3V5tY4QVtiZLtMAat8KZRrw8PUT+H7KegoXLsTAgW157LHmhIXl/FMPQdGYbYwx+VZiPGyZBgtehd2L064rVBSueBca9kgtnph8Ohm88cZVFCoUyttvd6BKlezdAuuNJQpjjAmEI//Ajj9g0WDYs+TM9e1GQsP7ITQcgMOHT/LCC7+wYcMBZsy4ExGhdu0yfP31LX4P1RKFMcbktiXDYfajaZdFRkObt6ByWyhR/fRiVeXrr9fw+OMz2LnzGKGhwrJlu2jatEKuhWuJwhhj/CnhOPz9A/z8MESWdhqpj8Wmrq/dDYpWglavQ2ihNJv+/fcB+vSZzowZmwBo0aISY8Z0pVGj8rn5CixRGGOMXxzaDEvehaXDU5edPJC2TM+dUCTjO5sGD/6D/v1nc/JkIiVLRvLGG1dx//0XERIi/os5E5YojDEmJ2kyrHgf5jwBiSdSl1dtDxd0geqdnfni1c64gvAUF5fAyZOJdO/eiMGDO1CuXBH/xu2FJQpjjMmOk4fgwwugUDFn/ui21HWVWkOxytDseYiu63U3e/ceZ/36/Vx+udOf3dNPt6Rt22q0bl3VT4H7zhKFMcacC1X45yf4xh1N4eTBtOuLV4VbfoGQUK+7SU5WPvpoKU89NZOwsBDWretD6dJRRESE5YkkAZYojDHm7CQlwN+TYcY9TkN1igu6OLe0AoSEQ9Gs70patWoPPXtO4fffnY6027e/gLi4BEqXzrnuN3KCJQpjjPHVvlXwScMzl7d8BZo/7/Nujh8/xcCBvzJkyHwSE5MpX74I777biW7d6iOS+43VWbFEYYwxWflnFqz6GNZ9nrpMQuGix6D1m1lWL6V3881fM2PGJkSgd+8YXn21HSVLRuZw0DnHEoUxxnhzeCtMbJ922fWToca5Dwb09NMt2b37GKNHd6FZs0rZiy8XWKIwxhiA+MOwYWLaW1oXvgXxh5zpyNJQ+zZo9iwU8/3DPTExmeHDF7B16yGGDr0agLZtq7Fo0YMBeSbiXFiiMMYUbAlx8NUVsOsv7+Vq3wpXjTyrXf/11w4eemgKy5btAuDBBy+mfv1yAEGTJMAShTGmIEuMh0ld0yaJck3h/MtS54ueD40egqhon3d76NBJnnvuZ8aMWYQqVK1aghEjOp9OEsHGEoUxpmBaMAh+ezZ1vmhF+M96KJS9J6AnTFjF44/PYPfu44SFhfDkky3o3781RYqEZzPgwLFEYYwpGPatho3fwB8vOeM8JBxLXVemAdy1xGuXGr766ae/2b37OC1bVmb06C40bJi7Hfj5gyUKY0zB8EmD1OmEY4BA9U7QaRwUPvcqofj4RHbsOMoFF5QC4M0329OqVRXuuadJULVDeGOJwhiTPyWcgC8ug4MbIDEudXmdO6DRg3BeTLarmX75ZQu9ek0lJERYvrwn4eGhlClTmPvua5rN4POWnB9c1Rhj8oKDG2DvsrRJonA56PI/qNwmW0li9+5jdO8+iXbtPmXDhv0AxMYeyWbAeZddURhj8pe4fTC6LIS4H2/R9eHOBc50Nq8gkpOV999fzDPP/MyhQyeJjAzjhRda0a9fS8LDz+7p7GBiicIYE1yO74YFr8GaT9J2ypciOTHt72odsp0gUtxww5dMnrwegI4dazByZGdq1CidI/vOyyxRGGPyvkObYe14WDzEeYLaF5f9H1z6DITm3G2pN95Yh7/+2sHQoZ245ZZ6ebIDP3+wRGGMydv2r4Vx9c5c3uEDqHd3xttIyFl31JeRyZPXExt7hN69LwHg7rsbc+ONdSlWLCLb+w4mliiMMXnT0Vj46QHYOiN12SVPQd07necexH/34mzbdphHH53O99+vJyIilE6danLBBaUQkQKXJMAShTEmLzq+Cz5tDCcPpC676Seo1j7zbXJAQkISw4Yt4KWX5nD8eALFioXzyitXUrVqCb8eN6+zRGGMyXv+HJiaJP6zEUrV9Psh58+P5aGHprBixW4AbrmlHu+805GKFYv7/dh5nSUKY0zes3y08zuydK4kCYD+/WezYsVuqlcvyYgRnencuVauHDcYWKIwxuQtpzz6YLphqt8Oo6ocPXqK4sWdNocRI67m00+X8/zzrSlcOPt9PuUnliiMMYGjyZB40pnevQg2T4OFb6Sur9DML4ddv34fvXtPQwRmzuyOiFC7dhlefbWdX44X7CxRGGNyX2I8nDoM4xrAib0Zl6ncFnL4OYWTJxN5/fV5DBr0O6dOJREdHcXWrYeoXr1Ujh4nv7FEYYzxr8STkHTKmY6dCwvfhB3z0pYJi3J+R5SEpo9AkfOg7l05GsbMmX/Tu/c0Nm1yGsn/858mvPlme6KjC+focfIjvyYKEekEDAVCgQ9UdVC69VWAT4CSbplnVHWaP2MyxuSC5CSnK++VH8KvT2ZerkILaPs2nN/Cb6GoKj16TObjj5cBUK9eWcaM6UKrVlX9dsz8xm+JQkRCgZFAeyAWWCgik1V1jUexF4CvVHW0iNQDpgHV/BWTMSYXJJyAz5rCwfVpl4cXc36fOgodP4L69/j1obkUIkK1aiWJigrjxRfb0Ldvi3zdgZ8/+POK4lJgk6puBhCRCcB1gGeiUCDlJuUSwL9+jMcY42+q8O3VqUkivDicOgL3rIIy9XMtjGXLdrFz51Guvtq5xfXpp1vSvXsja4s4R/5MFBWB7R7zsUD6WxgGAD+JyCNAEeCqjHYkIg8CDwJUqVIlxwM1xuSA+CMwwuMJ5ivehYsey9UQjh6N56WX5jB06AKio6NYt64PpUtHERERZkkiGwI9cNHtwDhVrQR0Bj4TOfNaVFXfU9UYVY0pW7ZsrgdpjPHBjHtSpy/uCw0fyLVDqyqTJq2lXr1RvPPOfADuuKMhhQoF+iMuf/DnFcUOoLLHfCV3maceQCcAVf1TRCKBMsAeP8ZljMlpGyfBpu+c6Zj/Qpu3cu3Q//xziD59pjNlygbn8DHnM3ZsVy66qEKuxZDf+TNRLARqiUh1nARxG3BHujLbgHbAOBGpC0QCmdxUbYzJUxJPOv0xTb4Jds5PXZ6LSUJVuemmr1i8eCfFi0fw2mtX0rNnDKGhdiWRk/yWKFQ1UUT6AD/i3Pr6kaquFpGBwCJVnQw8CbwvIk/gNGzfq6rqr5iMMTkk4Th8UAPidqdd3n1Zrhw+OVkJCRFEhMGDOzBmzCLeeacjFSoUy5XjFzQSbJ/LMTExumjRokCHYUzBEH8kdUS5Td/B3uXO9K4FsG+VM13kPGeo0XtWQ5h/x2rYvz+OZ56ZBcD771/r12PlNyKyWFVjzmVbezLbmIIsMR7idqXOJ8TBvpWwZ6nzs/XHzLeVEGj2HLR82e9hqiqffrqc//53Jvv2xREeHspLL7WlUiXrAjw3WKIwpiBShWWj4LfnnOccslK0ktPvUskaUOdOCIuEqu2hSHm/h7p27V569ZrKr7/+A0DbttUYPbqLJYlcZInCmIJo4lWw7RdnWkKhaEVnOiQMoutCuaZQvBqEFYaa10OhqFwPUVV58cXZvPHG7yQkJFOmTGHefrsD3bs3QnK4s0DjnSUKYwqCpASY84TT3rBnCex3O0ioeQN0nQCh4YGNLwMiwo4dR0lISOaBBy5i0KCrKF069xOWsURhTP6iyXB4i9Mpn+eycXXPLFv+YujyeZ5KEv/+e5R9++Jo1Mip0nrzzfb06NGUli2tR4ZAskRhTH5wYj/E7YHf+8PGb7yXvfpTZ4jR6p1zfLyHc5WUlMzo0Yt4/vlfqFixGMuW9SQ8PJQyZQpTpowliUCzRGFMMFKFDV87t6we3OiMDuep6PnOLaspkhOhbJM8Wc20ZMlOHnpoCosWOX2Ctm5dlSNH4ilTxsaJyCssURgTbE4dg++vh20/n7muSjto8SJUap3rYZ2tI0fi6d//F0aMWEhyslKpUnGGDevE9dfXscbqPMbnRCEihVU1zp/BGGO8SIiDNZ/BL49AcoKzrFxTuOhxKFQYqlwFkSUDGaHPVJXWrT9m+fLdhIYKffs2Z8CAthQr5t8H9sy5yTJRiMhlwAdAUaCKiDQGHlLV3v4Ozhjj2rMMxl/sNEynqH8vdPo4UBFli4jwxBPNGTVqEWPHdqVJk/MCHZLxIssuPERkAXAzMFlVm7rLVqlqg1yI7wzWhYcpUA79DV9dAUc9hnYpch60egNq3ZA6alwed+pUEkOG/EloqNCvX0vAuapITlbrwC+X+L0LD1Xdnq7OMCmzssaYHDQ+BuIPpc4/sA2KV860eF40b94/9Ow5lTVr9hIREcrddzemfPmiiAihodYWEQx8SeXb3eonFZFCIvJfYK2f4zKmYDu0Gb64PDVJNOgBjx4PqiSxb18c//nP97RuPY41a/ZSq1Zppky5g/LliwY6NHOWfLmi6AkMxRnadAfwE2DtE8b4S+xc+LJN6ny7UdCkV+DiOUuqyrhxy+jXbyb7958gPDyUZ5+9nGeeuZzISLvRMhj58lerrap3ei4QkZbA7/4JyZgC7vsbUqcvfTaokkSK8eNXsn//Ca68sjqjRnWmdu0ygQ7JZIMviWI4cJEPy4wx2bVnuTNqHMCVI6Dpw4GNx0dxcQkcPnySChWKISKMGtWZhQv/5c47G9ozEflApolCRFoAlwFlRaSvx6riOCPWGWNyUvwR2PBV6nzjhwIXy1mYPn0jDz88jQsuKMXMmd0REWrXLmNXEfmItyuKcJxnJ8IAz3vwjuDcLmuMyQnJSfD3DzDZo8qpeX+ny+88bMeOIzz++I9MnOj0RFusWAT795+wrjfyoUzfiar6K/CriIxT1X9yMSZjCo7dS2F8ulrcKu2gXvfAxOODpKRkRo5cyAsv/MLRo6coUqQQAwdewaOPNiMszJ6JyI98+coSJyJvAfWByJSFqnql36IyJj87dRR2L4YD62FWz9TlVTtA+zFQonrgYstCcrLSps04fv/deQDw+uvrMHRoJ6pUKRHgyIw/+ZIo/gd8CXTFuVX2HmCvP4MyJl/SZNi1ED5vfua6tkOcPpvyeMNvSIjQoUMNtm07zIgRnbn22tqBDsnkAl+68FisqheLyApVbeQuW6iql+RKhOlYFx4mKCUchxn3woaJqctKVHd+Yv4L1a8OWGjeqCpffbWasLAQbrqpHgDx8YkkJCRTtGje6q7ceOfvLjzcbirZKSJdgH+B0udyMGMKpOQk+LAWHN+Zuuyix52riDx8BfH33wfo3XsaP/30N2XLFubKK6tTqlQUERFhRFgnrwWKL4niFREpATyJ8/xEceBxfwZlTL6yf01qkqjeGdqNyNPtEPHxibz11h+8+uo8Tp5MpFSpSF599UpKlIjMemOTL2WZKFR1ijt5GLgCTj+ZbYzJSlICfHGZM12kAtw4NbDxZGHOnK306jWVdev2AdC9eyMGD+5AuXJFstjS5GfeHrgLBW7F6eNphqquEpGuwHNAFNA0d0I0Joj9+l9IOOZMN7gvsLFkISkpmd69nSRRu3Y0o0d34Yor8u6Vj8k93q4oPgQqA38Bw0TkXyAGeEZVv8uF2IwJbjt+h6XDnOlileHyVwMbTwaSk5WTJxMpXLgQoaEhjB7dhblz/+Gpp1oSEZG3H/gzucfbOyEGaKSqySISCewCaqjq/twJzZggFrcXJlyeOv9A3ntmdeXK3fTsOZU6daL58MPrAGjTphpt2lQLbGAmz/GWKE6pOuMuqupJEdlsScIYL1Rh53xY9TGsfD91+c0z89TdTcePn2LgwF8ZMmQ+iYnJbNlykIMHT1CqVFSgQzN5lLdEUUdEVrjTAtRw5wXQlGcqjDGu356DvwalXXbHAqhwaWDiycAPP6ynT5/pbNt2GBHo3TuGV19tR8mSdkeTyZy3RFE316IwJpj90A0OrIF9q1KXXdAFWg+G6DqBi8tDYmIy3bpN5NtvncEpmzQ5j7Fju3LppRUDHJkJBt46Bcx7larG5CVrP4d5z8LRbWmX37saousFJqZMhIWFUKJEBEWLhvPyy1fQp8+l1oGf8VmWXXhka+cinXCGUQ0FPlDVQRmUuRUYACiwXFXv8LZP68LDBETiSdj6E8x/2bndNfEkHNmaur5kTbj2GyhaEaKiAxampwULYgFo1qwSAPv3x3HiRCKVKhUPZFgmQPzdhcc5cZ/DGAm0B2KBhSIyWVXXeJSpBTwLtFTVgyJSzl/xGOOTkwfhn1mgSc78holOT6+eSSFFREmoeQNc8hSUrp1nGqwPHTrJs8/OYuzYxdSpU4Zly3oSHh5KdLSNE2HOjU+JQkSigCqquv4s9n0psElVN7v7mABcB6zxKPMAMFJVDwKo6p6z2L8xOWf+K7DmMzi4wXu5yNJQ+zZo2gdKXABheafTI1Xliy9W0bfvj+zefZywsBCuvbY2SUnJ2KCUJjuyTBQicg0wGGfEu+oi0gQYqKrXZrFpRWC7x3ws0CxdmQvdY/yO804eoKozfAvdmGxKSoAt0yH+kFOllHQqdd15l3r0xyRw6TNQuBwUrRCISLO0ceN+eveexqxZmwFo2bIyY8Z0pUEDu0g32efLFcUAnKuDOQCqukxEcuq5/jCgFtAWqATMFZGGqnrIs5CIPAg8CFClSpUcOrQp8JYMhbn9UucrNIdO4yCqLEQFTwfJCQlJXHnlp8TGHqF06SjefPMq7ruvKSEheaMqzAQ/n7oZV9XDkrb+1ZcW8B04XYCkqOQu8xQLLFDVBGCLiGzASRwL0xxM9T3gPXAas304tjGZS0qAyTfC5impy+rfA00fcdoagoSqIiIUKhTKq69eyezZW3nzzasoW9Y68DM5y5f741aLyB1AqIjUEpHhwB8+bLcQqCUi1UUkHLgNmJyuzHc4VxOISBmcqqjNPsZuzLlZ82naJHHzTOdKovzFAQvpbOzefYzu3SfxyitzTy+7++7GfPzxdZYkjF/4kigewRkvOx74HKe78cez2khVE4E+wI/AWuArVV0tIgNFJKV940dgv4isAWYD/aybEOM3x3bC7Cdg5oPOfP174OGDUPWqwMblo+RkZezYRdSpM5Lx41cwZMh8jh6ND3RYpgDwZSjUi1R1SS7FkyV7jsKck3nPpu1eo/mLcNlLIMHx0Nny5bvo2XMq8+c7z0Z06lSTkSM7c8EFpQIcmQkW/n6O4m0ROQ+YCHypqquy2sCYPOXf+WmTxA1TnC42gkBCQhLPPvsz7747n6QkpUKFogwd2ombb66H5JHnNkz+58sId1e4ieJWYKyIFMdJGK/4PTpjskMVVrwHs3qmLnvsZJ569iErYWEhLF26i+Rk5ZFHLuXll6+wIUlNrvPpgTtV3YUzeNFs4CngRcAShcm7Nn4Hk29Iu+z6H4IiSWzbdpikpGSqVy+FiDBmTBcOH44nJub8QIdmCihfHrirC3QDbgL2A18CT/o5LmPOniqs/xJ2LYLFb6dd130plGsSkLB8lZCQxNChC3jppTm0aFGJmTO7IyLUqpU3+o4yBZcvVxQf4SSHjqr6r5/jMcY3uxc77Q7bfwVnfC04mcENczdOh+qdcje2c/Dnn9vp2XMqK1bsBqB06Sji4hIoUiQ8wJEZ41sbRYvcCMQYn506CuO93LxRoTmc3wKaPAwla+ReXOfg4METPPPMLN57z7mxsHr1kowc2Zmrr64V4MiMSZVpohCRr1T1VhFZSdonsW2EOxNYC15Pnb51NkQ3SJ0Pi4Tworkf0zmIj0+kSZOxbNt2mEKFQujX7zKef741hQsXCnRoxqTh7YriMfd319wIxBivVOHbzvDv784VBUDnz6Fy24CGlR0REWH06NGUn3/ewujRXahXr2ygQzImQ5k+baSqO93J3qr6j+cP0Dt3wjMGJ0nMewa2zkhNEqXrwoU3BTaus3TyZCIvvTSbzz9feXrZc8+1Ys6ceyxJmDzNl8bs9sDT6ZZdncEyY3LerkXw50DY/IMzX6wK3LMSChWBkOAZY2HmzL/p3XsamzYdoFy5ItxwQx2iogrZcKQmKHhro+iFc+VwgYis8FhVDPjd34GZAu73/rBosDPkaIoqV8E1X0FE8AzluWvXMfr2/ZEvvnA6NKhfvyxjxnQlKsraIUzw8HZF8TkwHXgdeMZj+VFVPeDXqEzBdeoYLHg1bZcbF/eFxr2gVM3AxXWWkpKSGTt2Mc899zOHD8cTFRXGSy+14YknWhAeHjxXQsaA90ShqrpVRB5Ov0JESluyMDni4Eb4vHlq20NyQuq6Rg9Cu1FBVcWUIilJGT78Lw4fjqdz51qMGHE11atbB34mOGV1RdEVWIxze6xnD2QKXODHuEx+d3QH/Pww/P19xuvbvA0xfXM3pmw6ejSepCSlZMlIwsNDef/9a9i9+xg33ljXOvAzQS3TRKGqXd3fOTXsqSnoTh2FlR/Cms9gj0fP9SFhcPsfULaxMy+hQXUVoapMmrSORx+dTseONfjww+sAuPxyG7bX5A++9PXUElimqsdF5C7gIuBdVd3m9+hM/jL5Zvjnp7TLLnnauXIoXC4wMWXT1q2HeOSR6UyZsgGAVav2cvJkIpGRPvW3aUxQ8OXdPBpoLCKNcToD/AD4DGjjz8BMPpJ0CpaPSZsk2rzttEEEyVPU6SUkJDFkyJ/83//9yokTiRQvHsFrr11Jz54xhIbaLa8mf/ElUSSqqorIdcAIVf1QRHr4OzATxJI8GqRP7IOxHt1jh0bAfzZC8cq5H1cOiYtLoHnzD1i5cg8At93WgCFDOlChQrEAR2aMf/iSKI6KyLNAd6CViIQAdhO4ydjnzWHngszX378FilbIvXj8oHDhQsTEnE9cXAKjRnWhQ4e83fGgMdnlS6LoBtwB/EdVd4lIFeAt/4ZlgtLelWmTRIj79kpOhLp3Qfv3oFBUYGLLBlXl00+XU6NG6dMN1O+805Hw8FB7cM4UCL50M75LRP4HXCIiXYG/VPVT/4dmgsqS4TD70dT5JzXzskFk7dq99Oo1lV9//Ye6dcuwbFlPwsNDbThSU6Bk2eomIrcCfwG34IybvUBEbvZ3YCZIaHLaJFH0fHjgn8DGlANOnEjghRd+oXHjMfz66z+ULVuYZ5+9nEKFrKHaFDy+VD09D1yiqnsARKQsMAuY6M/ATBBIToKP68ChTanLHoyFIH+4bMaMTTz88DQ2bz4IwAMPXMSgQVdRunTwVZsZkxN8SRQhKUnCtR8frkRMPrdpMnx/Xer8xU9Cw/uDPkkcO3aK7t0nsW9fHA0alGPMmC60bGkPzpmCzZdEMUNEfgS+cOe7AdP8F5LJ0xLjYd8K+MFjLIiGD0DbwYGLKZuSkpJJTlYKFQqlaNFwhg7tRGzsEZ54ojmFCgXPE+LG+Isvjdn9RORG4HJ30XuqOsm/YZk8R5Nh/quw8A1IOO4siyoDN0yBCs0CG1s2LF78Lw89NIXrrqtN//7OM6R33NEwwFEZk7d4G4+iFjAYqAGsBP6rqjtyKzCThxxY77RFpAgJgxrXQfuxEBUduLiy4ciRePr3/4URIxaSnKwcORLPM89cblcQxmTA2xXFR8CnwFzgGmA4cGNuBGXykL+npG2LiK4H96wK2rYIVWXixDU89tgMdu48Rmio0Ldvc/7v/66wJGFMJrwlimKq+r47vV5Elngpa/KbPcthybuwepwzX6wydP0Kzm8eyKiy5ejReLp1m8j06c5dWs2aVWTMmK40aXJegCMzJm/zligiRaQpqeNQRHnOq6oljvwoMR5+6QMrP0hd1vABaDskaDvwS1G0aDjx8UmUKBHBoEFX8eCDFxMSEpxXRsbkJm+JYicwxGN+l8e8Alf6KygTIOsmwNTbU+fLNoY2g6HqVYGLKZvmzv2HChWKUqtWNCLCRx9dS2RkGOXLB3fSMyY3eRu46IrcDMQE2MqP4CePToEv6ArXTUrtrynI7NsXx1NPzeTjj5fRrl11Zs7sjohQtWrJQIdmTNAJzk8Bk31xeyExzukGfOmI1LYIgPvWQ+kLAxZadiQnK+PGLaNfv5kcOHCC8PBQWrWqQlKSEhZm1UzGnAu/JgoR6QQMBUKBD1R1UCblbsLpEuQSVV3kz5gMsPYLmHZHxuseOQLhwTmuwurVe+jVayrz5jmDL7ZrV51Ro7pw4YXBeQuvMXmF3xKFiIQCI4H2QCywUEQmq+qadOWKAY8BXgYxMDlq64zU6WJV4NRhqHkDXPJU0CaJw4dP0rz5hxw7dopy5YowZEgH7rijIRKkt/Eak5f4Mma2AHcCF6jqQHc8ivNU9a8sNr0U2KSqm939TACuA9akK/cy8AbQ72yDN2dJFea/AmvcXuLvXe08FxHEVBURoUSJSJ5+uiU7dhzhtdfaUaqUdeBnTE7xpXO/UUALIOV2mKM4VwpZqQhs95iPdZedJiIXAZVVdaq3HYnIgyKySEQW7d2714dDmwwdWAd/vOhMR5WB0nUDG0827NhxhJtv/orx41ecXvb8860YPbqrJQljcpgviaKZqj4MnARQ1YNAeHYP7A6pOgR4MquyqvqeqsaoakzZsmWze+iC68Da1Olu84Ly6erExGSGDp1PnToj+eabtbz00hySkpIBrJrJGD/xpY0iwW1vUDg9HkWyD9vtACp7zFdyl6UoBjQA5rj/4OcBk0XkWmvQ9oNvO8OW6c50pdYQXcd7+Txo4cId9Ow5lSVLdgJw/fV1GDasE6Gh1uu9Mf7kS6IYBkwCyonIq8DNwAs+bLcQqCUi1XESxG04Y28DoKqHgTIp8yIyB6fjQUsSOW3ngtQkAXD1Z4GL5RwcP36Kp5+exahRC1GFKlVKMHz41Vx7be1Ah2ZMgeBLN+P/E5HFQDuc7juuV9W1WWyGqiaKSB/gR5zbYz9S1dUiMhBYpKqTsxm78dUWj7ucHj0GhYoELpZzEBYWwqxZmwkJEfr2bcFLL7WhSJFs134aY3wkquq9gHOX0xlUdZtfIspCTEyMLlpkFx1ZUoXf+8P+1bDpO2dZ455w1eiAhuWrv/8+QMmSkURHFwacaqfIyDAaNiwf4MiMCU4islhVY85lW1+qnqbitE8IEAlUB9YD9c/lgCYXJCU4fTZt/CZ1WUgYtHojcDH5KD4+kbfe+oNXX53HnXc25IMPrgXgkksqZrGlMcZffKl6SjPcl3tLa2+/RWSy59i/MPep1CRRoQXEPAnnXQIRxQMbWxbmzNlKr15TWbduH+Dc4ZSUlGyN1cYE2Fk/ma2qS0QkeMe+zM8O/e2MRJec6MxfMRQuejSwMflgz57j9Os3k08/XQ5A7drRjB7dhSuuqB7gyIwx4NuT2X09ZkOAi4B//RaROTc7F8DnHoMKtXoDmvYJXDw+2rcvjrp1R3LgwAkiIkJ5/vlWPPVUSyIirL9KY/IKX/4bPTv/ScRps/gmk7ImEI7tTJsk2gx2qpuCQJkyhbnuutrExh5h1Kgu1KxZOtAhGWPS8Zoo3Aftiqnqf3MpHnM2DqyHP16C9V+mLmsxAJrm3eqm48dPMXDgr3TpciGtW1cFYNSoLkREhNqT1cbkUZkmChEJc5+FaJmbARkvNBn2LHNue01OgH2r4PjO1PXNnoMWL+bZrjl++GE9ffpMZ9u2w0ydupEVK3oREiJERlo1kzF5mbf/0L9w2iOWichk4GvgeMpKVf3Wz7GZFMlJsGOec8vr8V1p15VtBK0GQclaUKpmYOLLwvbth3nssRlMmrQOgKZNz2Ps2K42XrUxQcKXr3KRwH6cMbJTnqdQwBKFv+1f53TkN+0uZzS6FBVaQNHznQfoKraCsIjAxehFYmIyw4Yt4MUXZ3P8eAJFi4bzyitX8PDDlxIWZre8GhMsvCWKcu4dT6tITRApvD/Obc6dKuxZCkuGpo4bkaJiK7joMbjwpsDEdpaOHInn9dd/4/jxBG66qS7vvtuJSpXy9rMcxpgzeUsUoUBR0iaIFJYoctqmybDkXdi30hnH2tN5l8BlA6F6p4CEdjYOHTpJVFQYERFhlC4dxdixXYmICKVLl+Acg9sY4z1R7FTVgbkWSUGUnAQzH4SDG2DHb2nXFS4HVTtAp3EQEhqQ8M6GqvLFF6t44okf6dPnEvr3bwPAjTcG7+BIxhiHt0RhLY3+osmw9UdnjIj0rp8MxSpDuSa5Hta52rBhP717T+Xnn7cAMHfuttNDlBpjgp+3RNEu16IoSJYMg9mPnbn81jlQujYUOS/XQzpXJ08m8sYbv/Haa79x6lQSpUtH8dZb7bn33iaWJIzJRzJNFKp6IDcDKRCO7UybJIpUgJt+hLINM98mj9q16xitW3/Mxo3O2+Tee5vw1lvtKVOmcIAjM8bkNHvSyd9UnX6Y/hzgVDeluPMvKB+TZx+Oy0r58kWoXLkEYWEhjB7dhTZtqgU6JGOMn1ii8AdV2LPE6V5j7wo4uj3t+osed+5kCiLJycr77y/miiuqc+GF0YgIn39+I6VKRREenvcb240x584ShT8sHQazH0+dD4uEKu3g/JZQvbPzNHUQWb58Fz17TmX+/FjatavOzJndERHKly8a6NCMMbnAEkVOO74bfns+db52N7j6MwgtFLiYztGxY6cYMGAO7747n6Qk5fzzi9Gz5zmNpGiMCWKWKHLCqaPOk9SbvoPdi51lRc6DB/6B0PCAhnauvvtuHY88Mp3Y2COEhAiPPHIpr7xyJcWL583uQowx/mOJIjuO/ONcPfz9A5w6knZd+/eDNkns2HGE226bSHx8EhdfXIExY7oSE3N+oMMyxgSIJYrsmNgRDq53pis0h+b9nc76ipwXVM9DACQkJBEWFoKIULFicV599UrCw0Pp3fsSG7PamALOEsW52vhtapK4cTpU6xi0t7r+8cd2evacQr9+l9G9e2MAnnzysgBHZYzJK+yr4rk4sh0muz24Firq3NEUhEniwIETPPTQD7Rs+RErV+5h1KhFqFp/j8aYtOyK4mz9+yd84fFt+/7NQXdHk6oyfvwKnnzyJ/bujaNQoRCeeqolzz/fyrreMMacwRKFL04dgy3TIfEEzLgndfk1X0PhsoGL6xzs3n2M22//htmztwLQpk1VRo/uQt26wfU6jDG5xxJFVhLi4LMmcOjvtMuvnww1rglISNlRsmQkO3ceo0yZwgwe3J67725sVxHGGK8sUWRl8ZC0SaLunVC1fVAliZkz/+aiiyoQHV2YiIgwvv76FipUKEp0tHXgZ4zJmiWKrPwzy/ktIfDwAYgoEdh4zsLOnUfp2/cnJkxYRY8eTfngg2sBaNCgXIAjM8YEE0sU3mycBLG/OtPtRgZNkkhKSmbs2MU8++zPHDkST1RUGLVrR9tgQsaYc2KJIiMJx2FSV9g+J3XZhbcEKpqzsmTJTnr2nMLChf8C0KVLLUaM6Ey1aiUDG5gxJmhZokgv/ghMuyttkrhjAURFByoin23deohLL32fpCSlYsViDBt2NTfcUMeuIowx2eLXRCEinYChQCjwgaoOSre+L3A/kAjsBf6jqv/4M6YsjfCoXmr5sjN2RHhwdKddrVpJ7ruvCcWKRfB//9eWYsWsAz9jTPb57clsEQkFRgJXA/WA20WkXrpiS4EYVW0ETATe9Fc8Ptn+a+p08Wpw8RN5Okls3XqIa675gl9/3Xp62XvvXcOQIR0tSRhjcow/ryguBTap6mYAEZkAXAesSSmgqrM9ys8H7vJjPN6pwldtU+cf2BKwULKSkJDEkCF/8n//9ysnTiSyb18cf/7ZA8CqmYwxOc6fiaIi4DkGaCzQzEv5HsD0jFaIyIPAgwBVqlTJqfjS+uen1OmbZvjnGDngt9+20bPnFFav3gvAbbc1YMiQDgGOyhiTn+WJxmwRuQuIAdpktF5V3wPeA4iJicnZXusOboRJXZzfKarmvQ/egwdP0K/fTD78cCkANWqUYtSoLnToUCPAkRlj8jt/JoodQGWP+UrusjRE5CrgeaCNqsb7MZ6MbZ+dNklc932e7Ak2OVn5/vv1FCoUwjPPXM6zz15OVFRwdUZojAlO/kwUC4FaIlIdJ0HcBtzhWUBEmgJjgU6qusePsWTs0N8w8yFnunEvaPsOhOWdRuB16/ZRvXpJIiLCiI4uzP/+dyNVqpSgTp0ygQ7NGFOA+O2uJ1VNBPoAPwJrga9UdbWIDBSRa91ibwFFga9FZJmITPZXPGfY8A18WDN1vlLrPJMk4uISeP75n2nUaDRvvvn76eUdOtSwJGGMyXV+baNQ1WnAtHTLXvSYvsqfx8/UL4/C0uGp8xc9lmc6+ZsxYxO9e09ly5ZDAOzbFxfYgIwxBV6eaMzOVQkn0iaJPNJd+L//HuXxx2fw9dfO3cMNG5ZjzJiuXHZZ5Sy2NMYY/ypYiWLPcph2Z+p83+Q80XC9YcN+YmLe4+jRUxQuXIgBA9rw+OPNKVQoNNChGWNMAUkUp47Cqo9g9uOpyyq2yhNJAqBWrdJccklFihQpxPDhV1O1aslAh2SMMafl/0Sx8VuY2RNO7E1d1uIlaPRgwEI6ciSeF1+cTe/el3DhhdGICJMn30aRIuEBi8kYYzKTvxPF1h9h8k2p8xICt/wClTN8rs/vVJWJE9fw2GMz2LnzGOvW7WPGDKfXEksSxpi8Kn8nip8fTp1uNQga3h+w7sI3bz5Inz7TmD59EwDNm1fijTcCc9OXMcacjfybKJISUse67vw/qHuH9/J+cupUEoMH/8HLL8/l5MlESpaMZNCgdjzwwMWEhOSNNhJjjPEm/yaKpcNSpysFpqoJYPv2wwwc+Cvx8UnceWdD3n67A+XL592uy40xJr38lyjij8DyMTDv6dRlxSrmaggHD56gZMlIRIQaNUozdGgnatYsTbt2F+RqHMYYkxP81oVHwMx/JW2SuHlWrh06OVn56KOl1Kw5nPHjV5xe/tBDMZYkjDFBK38likObYdFbznSZhtDlC6jaLlcOvXr1Htq2HUePHpM5cODE6UZrY4wJdvmn6inpFHzoMTZD96UQ4v8nm+PiEnj55V8ZPPhPEhOTKVeuCO+805Hbb2/g92MbY0xuyD+JYtfC1Olrv8mVJLFhw346dhzP1q2HEIGePS/mtdfaUapUlN+PbYwxuSV/JIrY3+DLVs70BddArRtz5bBVq5YgMjKMxo3LM2ZMV5o3r5QrxzXBISEhgdjYWE6ePBnoUEwBEhkZSaVKlShUKOcGNgvuRJGcCD89AKvHpS6rfavfDpeYmMyYMYu4/fYGREcXJiIijBkz7qRixeKEheWv5h6TfbGxsRQrVoxq1aoheaRfMZO/qSr79+8nNjaW6tWr59h+gzdRnNgPo9IN4tPxI7jwFr8c7q+/dtCz5xSWLt3FsmW7+OADZ+wl68DPZObkyZOWJEyuEhGio6PZu3dv1oXPQvAminH1UqfDIqHXHggvluOHOXz4JM8//wujRi1EFapUKcF119XO8eOY/MmShMlt/njPBW+iiCgJcXug/n3Q6aMc372q8uWXq3niiR/ZtesYYWEh9O3bnBdfbGMd+BljCpTgrVhPcIcIbf6CX3a/fPlubr/9G3btOsZll1VmyZIHeeON9pYkTFAJDQ2lSZMmNGjQgGuuuYZDhw6dXrd69WquvPJKateuTa1atXj55ZdR1dPrp0+fTkxMDPXq1aNp06Y8+eSTAXgF3i1dupQePXoEOoxMxcfH061bN2rWrEmzZs3YunVrhuUOHTrEzTffTJ06dahbty5//vknAF9//TX169cnJCSERYsWnS6/cuVK7r333lx4BY7gTBTxR+BYLISGQ/EqObbbpKTk09NNmpzHE0805/33r2HevPto2LB8jh3HmNwSFRXFsmXLWLVqFaVLl2bkyJEAnDhxgmuvvZZnnnmG9evXs3z5cv744w9GjRoFwKpVq+jTpw/jx49nzZo1LFq0iJo1a+ZobImJidnex2uvvcajjz6aq8c8Gx9++CGlSpVi06ZNPPHEEzz99NMZlnvsscfo1KkT69atY/ny5dStWxeABg0a8O2339K6des05Rs2bEhsbCzbtm3z+2uAYK162u+MK03puhCSMy9h9uwt9O49jbFju9K6dVUAhgzpmCP7Noa3/dRW8aRmXcbVokULVqxwupb5/PPPadmyJR06dACgcOHCjBgxgrZt2/Lwww/z5ptv8vzzz1OnTh3AuTLp1avXGfs8duwYjzzyCIsWLUJEeOmll7jpppsoWrQox44dA2DixIlMmTKFcePGce+99xIZGcnSpUtp2bIl3377LcuWLaNkyZIA1KpVi99++42QkBB69ux5+oPw3XffpWXLlmmOffToUVasWEHjxo0B+Ouvv3jsscc4efIkUVFRfPzxx9SuXZtx48bx7bffcuzYMZKSkpg2bRqPPPIIq1atIiEhgQEDBnDdddexdetWunfvzvHjxwEYMWIEl112mc/nNyPff/89AwYMAODmm2+mT58+qGqadoTDhw8zd+5cxo0bB0B4eDjh4U7NRUrCyMg111zDhAkTeOqpp7IVoy+CNFGsdn6Xyf7Tz3v2HKdfv5l8+ulyAIYM+fN0ojAmv0hKSuLnn38+XU2zevVqLr744jRlatSowbFjxzhy5AirVq3yqarp5ZdfpkSJEqxcuRKAgwcPZrlNbGwsf/zxB6GhoSQlJTFp0iTuu+8+FixYQNWqVSlfvjx33HEHTzzxBJdffjnbtm2jY8eOrF27Ns1+Fi1aRIMGqZ8BderUYd68eYSFhTFr1iyee+45vvnmGwCWLFnCihUrKF26NM899xxXXnklH330EYcOHeLSSy/lqquuoly5csycOZPIyEg2btzI7bffnqa6J0WrVq04evToGcsHDx7MVVelHWNmx44dVK5cGYCwsDBKlCjB/v37KVMm9Y7NLVu2ULZsWe677z6WL1/OxRdfzNChQylSpIjX8xgTE8OgQYMsUWRq3yrnd3T9c95FcrLy4YdLePrpWRw8eJKIiFBeeKE1/fpl7xuEMRk6i2/+OenEiRM0adKEHTt2ULduXdq3b5+j+581axYTJkw4PV+qVKkst7nlllsIDXV6TujWrRsDBw7kvvvuY8KECXTr1u30ftesWXN6myNHjnDs2DGKFk3ton/nzp2ULVv29Pzhw4e555572LhxIyJCQkLC6XXt27endOnSAPz0009MnjyZwYMHA85tzNu2beP888+nT58+LFu2jNDQUDZs2JBh/PPmzcvyNZ6NxMRElixZwvDhw2nWrBmPPfYYgwYN4uWXX/a6Xbly5fj3339zNJbMBHeiOMcrii1bDnLXXZP444/tAHToUIORIztTs2bpnIrQmDwhpY0iLi6Ojh07MnLkSB599FHq1avH3Llz05TdvHkzRYsWpXjx4tSvX5/FixefrtY5W55VK+mfTPf8ptyiRQs2bdrE3r17+e6773jhBefmlOTkZObPn09kZKTX1+a57/79+3PFFVcwadIktm7dStu2bTM8pqryzTffULt22tvcBwwYQPny5Vm+fDnJycmZHvtsrigqVqzI9u3bqVSpEomJiRw+fJjo6LSjbFaqVIlKlSrRrFkzwKmiGjRoUKavO0VKFVtuCM7G7GxWPRUvHsGGDfs577yiTJhwEzNm3GlJwuRrhQsXZtiwYbz99tskJiZy55138ttvvzFrltMN/4kTJ3j00UdPV2P069eP11577fS36uTkZMaMGXPGftu3b3+6gRxSq57Kly/P2rVrSU5OZtKkSZnGJSLccMMN9O3bl7p1657+EO3QoQPDhw8/XW7ZsmVnbFu3bl02bUrtpfnw4cNUrOiMPZNS35+Rjh07Mnz48NN3eC1duvT09hUqVCAkJITPPvuMpKSkDLefN28ey5YtO+MnfZIAuPbaa/nkk08Ap63myiuvPOM5h/POO4/KlSuzfv16AH7++Wfq1at3xr7S27BhQ5qqN38KvkShCsd3Oo3YxX1vS/jxx03Exzt3PERHF2by5NtYt+5hunVrYA9FmQKhadOmNGrUiC+++IKoqCi+//57XnnlFWrXrk3Dhg255JJL6NOnDwCNGjXi3Xff5fbbb6du3bo0aNCAzZs3n7HPF154gYMHD9KgQQMaN27M7NmzARg0aBBdu3blsssuo0KFCl7j6tatG+PHjz9d7QQwbNgwFi1aRKNGjahXr16GSapOnTocPnz49Lf7p556imeffZamTZt6vbupf//+JCQk0KhRI+rXr0///v0B6N27N5988gmNGzdm3bp1WbYR+KJHjx7s37+fmjVrMmTIkNNXCv/++y+dO3c+XW748OHceeedNGrUiGXLlvHcc88BMGnSJCpVqsSff/5Jly5d6Ngx9Qab2bNn06VLl2zH6AvxvG86GMRcfJEuumMphEbA41l3trZ9+2EefXQG3323jpdfvoIXXmid5TbG5IS1a9d6vWvFZN8777xDsWLFuP/++wMdSq6Kj4+nTZs2/Pbbb4SFndmCkNF7T0QWq2rMuRwv+K4oUh60K+F9xLjExGSGDPmTunVH8t136yhaNJzSpa37b2Pyk169ehERERHoMHLdtm3bGDRoUIZJwh+CrzH71BHnd9Uz6wNTzJ8fS8+eU1i+fDcAN91Ul6FDO1GxYvHciNAYk0siIyPp3r17oMPIdbVq1aJWrVq5drzgTRRVMk4UCxbEctllH6IK1aqVZMSIq+nS5cJcDNCYVOkfrjLG3/zRnBB8iSLhOEgoVG6T4epLL61Ix441adr0PF54oTWFC+fc4B3GnI3IyEj2799PdHS0JQuTK1LGo/B2W/G5CL5EAVCmPkSUAGDjxv088cSPDBnSkQsvdP4hp069g5AQ+8c0gVWpUiViY2NzfGwAY7xJGeEuJwVnoogqR3x8IoMG/cbrr/9GfHwSkZFhTJzojG5nScLkBYUKFcrRUcaMCRS/3vUkIp1EZL2IbBKRZzJYHyEiX7rrF4hINV/2+/O2JjRqNIYBA34lPj6J++5rwpgxXXM8fmOMMX68ohCRUGAk0B6IBRaKyGRVXeNRrAdwUFVrishtwBtAtzP3lmrLgZJc9d+iwH7q1i3DmDFdrRM/Y4zxI39eUVwKbFLVzap6CpgAXJeuzHXAJ+70RKCdZNHqdzAuishweO21K1m2rKclCWOM8TO/PZktIjcDnVT1fne+O9BMVft4lFnllol15/92y+xLt68HgQfd2QbAKr8EHXzKAPuyLFUw2LlIZecilZ2LVLVVtdi5bBgUjdmq+h7wHoCILDrXx9DzGzsXqexcpLJzkcrORSoROXNwDR/5s+ppB1DZY76SuyzDMiISBpQA9vsxJmOMMWfJn4liIVBLRKqLSDhwGzA5XZnJwD3u9M3ALxpsvRQaY0w+57eqJ1VNFJE+wI9AKPCRqq4WkYHAIlWdDHwIfCYim4ADOMkkK+/5K+YgZOcilZ2LVHYuUtm5SHXO5yLouhk3xhiTu4Kvm3FjjDG5yhKFMcYYr/JsovBX9x/ByIdz0VdE1ojIChH5WUTy7VOIWZ0Lj3I3iYiKSL69NdKXcyEit7rvjdUi8nlux5hbfPgfqSIis0Vkqft/0jmj/QQ7EflIRPa4z6hltF5EZJh7nlaIyEU+7VhV89wPTuP338AFQDiwHKiXrkxvYIw7fRvwZaDjDuC5uAIo7E73Ksjnwi1XDJgLzAdiAh13AN8XtYClQCl3vlyg4w7guXgP6OVO1wO2BjpuP52L1sBFwKpM1ncGpgMCNAcW+LLfvHpF4ZfuP4JUludCVWerqjtGLPNxnlnJj3x5XwC8jNNvWNaDqgcvX87FA8BIVT0IoKp7cjnG3OLLuVAgZYjLEsC/uRhfrlHVuTh3kGbmOuBTdcwHSopIhaz2m1cTRUVgu8d8rLsswzKqmggcBqJzJbrc5cu58NQD5xtDfpTluXAvpSur6tTcDCwAfHlfXAhcKCK/i8h8EemUa9HlLl/OxQDgLhGJBaYBj+ROaHnO2X6eAEHShYfxjYjcBcQAGQ//l8+JSAgwBLg3wKHkFWE41U9tca4y54pIQ1U9FMigAuR2YJyqvi0iLXCe32qgqsmBDiwY5NUrCuv+I5Uv5wIRuQp4HrhWVeNzKbbcltW5KIbTaeQcEdmKUwc7OZ82aPvyvogFJqtqgqpuATbgJI78xpdz0QP4CkBV/wQicToMLGh8+jxJL68mCuv+I1WW50JEmgJjcZJEfq2HhizOhaoeVtUyqlpNVavhtNdcq6rn3BlaHubL/8h3OFcTiEgZnKqozbkYY27x5VxsA9oBiEhdnERREMeonQzc7d791Bw4rKo7s9ooT1Y9qf+6/wg6Pp6Lt4CiwNdue/42Vb02YEH7iY/nokDw8Vz8CHQQkTVAEtBPVfPdVbeP5+JJ4H0ReQKnYfve/PjFUkS+wPlyUMZtj3kJKASgqmNw2mc6A5uAOOA+n/abD8+VMcaYHJRXq56MMcbkEZYojDHGeGWJwhhjjFeWKIwxxnhlicIYY4xXlihMQIhIkogs8/ip5qXssRw43jgR2eIea4n7dO7Z7uMDEannTj+Xbt0f2Y3R3U/KeVklIj+ISMksyjfJbk+oIjJNREq6P72zsy+TP9ntsSYgROSYqhbN6bJe9jEOmKKqE0WkAzBYVRtlY3/Zjimr/YrIJ8AGVX3VS/l7cXrI7ZMDx66Gc44aZHdfJn+xKwqTJ4hIUXHG0lgiIitF5IxeYUWkgojM9fjG3cpd3kFE/nS3/VpEsvoAnwvUdLft6+5rlYg87i4rIiJTRWS5u7ybu3yOiMSIyCAgyo3jf+66Y+7vCSLSxSPmcSJys4iEishbIrJQnHEAHvLhtPyJ22GbiFzqvsalIvKHiNR2n0IeCHRzY+nmxv6RiPzllr3O3b6wiHwlztgUk8QZwyXGXbfVfXJ7EFDD3ddbPsRnCopA959uPwXzB+dJ4WXuzyScXgKKu+vK4Dw5mnLFe8z9/STwvDsditO3UxmcD/4i7vKngRczON444GZ3+hZgAXAxsBIogvNk+2qgKXAT8L7HtiXc33Nwx7dIicmjTEqMNwCfuNPhOD11RgEPAi+4yyOARUD1DOI85vH6vgY6ufPFgTB3+irgG3f6XmCEx/avAXe50yVx+ncqAvwXGOsubwAkeryWre55rEYm4xjYT8H+yZNdeJgC4YSqNkmZEZFCwGsi0hpIxvkmXR7Y5bHNQuAjt+x3qrpMRNrgDETzu9t9STjON/GMvCUiL+D08dMDp++fSap63I3hW6AVMAN4W0TewKmKmXcWr2s6MFREIoBOwFxVPeFWdzUSkZvdciVwOujbkm77KBFZ5r7+tcBMj/KfiEgtnC4oCmVy/A7AtSLyX3c+EqgCXA4MBVDVVSKy4ixekyngLFGYvOJOoCxwsaomiNP7a6RnAVWd6yaSLsA4ERkCHARmqurtPhyjn6pOTJkRkXYZFVLVDeKMa9EZeEVEflbVgb68CFU9KSJzgI5AN5xBdMAZUewRVf0xi12cUNUmIlIYp++ih4FhOIMxzVbVG9y2hDmZbC/ATaq6Ps3CfDmml8kt1kZh8ooSwB43SVwBnDHutzhjge9W1feBD3CGfJwPtBSRlDaHIiJyoY/HnAdc79bfF8GpNponIucDcao6HqfDxYzGFU5wr2wy8iVOZ2spVyfgfOj3StlGRC50j5khdUYsfBR4UlK70U/pDvpej6JHcargUvwIPCJuZhCnZ2GA34Fb3WX1gIYZHDb9vowBLFGYvON/QIyIrATuBtZlUKYtsFxEluJ8Wx+qqntxPji/cKtT/gTq+HJAVV2C03bxF06bxQequhTnQ/QvtwroJeCVDDZ/D1iR0pidzk84g0fNUmdoTnAS2xpgiTgD348liyt6N5YVOIPuvAm87r52z+1mA/VSGrNxrjwKubGtducBRgFlxelJ9hWc9pjD6Y63H6cKb5U1ZhtPdnusMQWAiIQChdyqsRrALKC2RyIzJlPWRmFMwVAYmO1WfQnQ25KE8ZVdURhjjPHK2iiMMcZ4ZYnCGGOMV5YojDHGeGWJwhhjjFeWKIwxxnj1/17hhq9DZ+AtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# best_clf.fit(X_train_new, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "\n",
    "y_pred_2 = best_clf_2.predict_proba(X_val_2)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val_2, y_pred_2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rategit ')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('./images/ensembling.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
